{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a378348",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6840,
     "status": "ok",
     "timestamp": 1648438388783,
     "user": {
      "displayName": "Naureen Hoque",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03798803644117143121"
     },
     "user_tz": 240
    },
    "id": "3a378348",
    "outputId": "c6498c63-a66e-4ff4-dd17-908886d09ff9"
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from math import floor\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score, roc_curve\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "from keras.utils import np_utils\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, BatchNormalization\n",
    "from keras.layers.core import Activation, Flatten, Dense, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import ELU, PReLU, LeakyReLU\n",
    "#from keras.layers.advanced_activations import ELU\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from math import floor\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "#from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.models import save_model\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.constraints import maxnorm\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "zXsyD8Tep5pL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1631,
     "status": "ok",
     "timestamp": 1648438390402,
     "user": {
      "displayName": "Naureen Hoque",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03798803644117143121"
     },
     "user_tz": 240
    },
    "id": "zXsyD8Tep5pL",
    "outputId": "a010ed1c-982b-4070-c1cc-8cfe98bc80e5"
   },
   "outputs": [],
   "source": [
    "NB_CLASSES = 4 # number of outputs = number of classes\n",
    "VERBOSE = 1\n",
    "BATCH_SIZE = 10\n",
    "NB_EPOCH = 100\n",
    "target_names = ['Non-MO', 'MO']\n",
    "file_short = \"D:/BMO/Main/savedModels/0input_model_short.h5\"\n",
    "file_mid1 = \"D:/BMO/Main/savedModels/0input_model_mid1.h5\"\n",
    "file_mid2 = \"D:/BMO/Main/savedModels/0input_model_mid2.h5\"\n",
    "file_long = \"D:/BMO/Main/savedModels/0input_model_long.h5\"\n",
    "file_best = \"D:/BMO/Main/savedModels/0input_model_best.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77f4de6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_length =   [1, 128, 1024, 1800, 2048]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3a06a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........Loading MO (2-state) dataset..........\n",
      "df_mo Shape =  (28000, 2049)\n",
      "CPU times: total: 1min\n",
      "Wall time: 1min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\".........Loading MO (2-state) dataset..........\")\n",
    "\n",
    "\n",
    "# sep separates each column and header = none means it is going to read from row 1\n",
    "re2psk_2st = pd.read_csv('D:/BMO/Main/bigDataset/SNR-based/BPSK-2/real_snr05.csv',sep=',', header=None) \n",
    "im2psk_2st = pd.read_csv('D:/BMO/Main/bigDataset/SNR-based/BPSK-2/im_snr05.csv',sep=',', header=None)\n",
    "\n",
    "# sep separates each column and header = none means it is going to read from row 1\n",
    "re4psk_2st = pd.read_csv('D:/BMO/Main/bigDataset/SNR-based/QPSK-2/real_snr05.csv',sep=',', header=None) \n",
    "im4psk_2st = pd.read_csv('D:/BMO/Main/bigDataset/SNR-based/QPSK-2/im_snr05.csv',sep=',', header=None)\n",
    "\n",
    "# sep separates each column and header = none means it is going to read from row 1\n",
    "re16qam_2st = pd.read_csv('D:/BMO/Main/bigDataset/SNR-based/16-QAM-2/real_snr05.csv',sep=',', header=None) \n",
    "im16qam_2st = pd.read_csv('D:/BMO/Main/bigDataset/SNR-based/16-QAM-2/im_snr05.csv',sep=',', header=None)\n",
    "\n",
    "# sep separates each column and header = none means it is going to read from row 1\n",
    "re64qam_2st = pd.read_csv('D:/BMO/Main/bigDataset/SNR-based/64-QAM-2/real_snr05.csv',sep=',', header=None) \n",
    "im64qam_2st = pd.read_csv('D:/BMO/Main/bigDataset/SNR-based/64-QAM-2/im_snr05.csv',sep=',', header=None)\n",
    "\n",
    "\n",
    "#merge two dataframes into one\n",
    "df2psk_2st = re2psk_2st + im2psk_2st * 1j\n",
    "df2psk_2st['Mod'] = 0 # 0 = BPSK 2-state\n",
    "#merge two dataframes into one\n",
    "df4psk_2st = re4psk_2st + im4psk_2st * 1j\n",
    "df4psk_2st['Mod'] = 1 # 1 = QPSK 2-state\n",
    "#merge two dataframes into one\n",
    "df16qam_2st = re16qam_2st + im16qam_2st * 1j\n",
    "df16qam_2st['Mod'] = 2 # 2 = 16-QAM 2-state\n",
    "#merge two dataframes into one\n",
    "df64qam_2st = re64qam_2st + im64qam_2st * 1j\n",
    "df64qam_2st['Mod'] = 3 # 3 = 64-QAM 2-state\n",
    "\n",
    "# combine all\n",
    "df_2st = df2psk_2st.append(df4psk_2st)\n",
    "df_2st = df_2st.append(df16qam_2st)\n",
    "df_2st = df_2st.append(df64qam_2st)\n",
    "\n",
    "#df_mo = df_2st\n",
    "#df_mo = df_mo.sample(frac = 1)\n",
    "print('df_mo Shape = ', df_2st.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89de8d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........Combining all data..........\n",
      "df_all Shape =  (28000, 2049)\n",
      "..........Shuffling done..........\n",
      "df_all Size =  57372000\n",
      "Dimension =  2\n",
      "Combined Shape =  (28000, 2049)\n"
     ]
    }
   ],
   "source": [
    "print(\"..........Combining all data..........\")\n",
    "\n",
    "# combine all\n",
    "#df = df_mo.append(df_nonmo)\n",
    "df_all = df_2st.sample(frac = 1)\n",
    "print('df_all Shape = ', df_all.shape)\n",
    "print(\"..........Shuffling done..........\")\n",
    "\n",
    "# reducing samples to tune only\n",
    "#df_all = df_all.iloc[:16384]\n",
    "print('df_all Size = ', df_all.size)\n",
    "print('Dimension = ', df_all.ndim)\n",
    "print('Combined Shape = ', df_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eeac3bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........Training set..........\n",
      "(20160, 1, 1)\n",
      "(20160,)\n",
      "..........Validation set..........\n",
      "(2240, 1, 1)\n",
      "(2240,)\n",
      "..........Testing set..........\n",
      "(5600, 1, 1)\n",
      "(5600,)\n",
      "Epoch 1/100\n",
      "620/630 [============================>.] - ETA: 0s - loss: 1.4050 - accuracy: 0.2509\n",
      "Epoch 1: val_accuracy improved from -inf to 0.26295, saving model to D:/BMO/Main/savedModels\\0input_model_best.h5\n",
      "630/630 [==============================] - 5s 5ms/step - loss: 1.4047 - accuracy: 0.2511 - val_loss: 1.3921 - val_accuracy: 0.2629\n",
      "Epoch 2/100\n",
      "628/630 [============================>.] - ETA: 0s - loss: 1.3907 - accuracy: 0.2487\n",
      "Epoch 2: val_accuracy did not improve from 0.26295\n",
      "630/630 [==============================] - 3s 4ms/step - loss: 1.3907 - accuracy: 0.2491 - val_loss: 1.3945 - val_accuracy: 0.2388\n",
      "Epoch 3/100\n",
      "624/630 [============================>.] - ETA: 0s - loss: 1.3907 - accuracy: 0.2494\n",
      "Epoch 3: val_accuracy did not improve from 0.26295\n",
      "630/630 [==============================] - 3s 4ms/step - loss: 1.3907 - accuracy: 0.2489 - val_loss: 1.3897 - val_accuracy: 0.2460\n",
      "Epoch 4/100\n",
      "621/630 [============================>.] - ETA: 0s - loss: 1.3906 - accuracy: 0.2436\n",
      "Epoch 4: val_accuracy did not improve from 0.26295\n",
      "630/630 [==============================] - 3s 4ms/step - loss: 1.3906 - accuracy: 0.2433 - val_loss: 1.3922 - val_accuracy: 0.2362\n",
      "Epoch 5/100\n",
      "618/630 [============================>.] - ETA: 0s - loss: 1.3904 - accuracy: 0.2453\n",
      "Epoch 5: val_accuracy did not improve from 0.26295\n",
      "630/630 [==============================] - 2s 4ms/step - loss: 1.3904 - accuracy: 0.2462 - val_loss: 1.3962 - val_accuracy: 0.2482\n",
      "Epoch 6/100\n",
      "623/630 [============================>.] - ETA: 0s - loss: 1.3899 - accuracy: 0.2475\n",
      "Epoch 6: val_accuracy did not improve from 0.26295\n",
      "630/630 [==============================] - 3s 4ms/step - loss: 1.3899 - accuracy: 0.2476 - val_loss: 1.3887 - val_accuracy: 0.2397\n",
      "Epoch 7/100\n",
      "615/630 [============================>.] - ETA: 0s - loss: 1.3897 - accuracy: 0.2503\n",
      "Epoch 7: val_accuracy did not improve from 0.26295\n",
      "630/630 [==============================] - 2s 4ms/step - loss: 1.3896 - accuracy: 0.2510 - val_loss: 1.3925 - val_accuracy: 0.2379\n",
      "Epoch 8/100\n",
      "628/630 [============================>.] - ETA: 0s - loss: 1.3898 - accuracy: 0.2470\n",
      "Epoch 8: val_accuracy did not improve from 0.26295\n",
      "630/630 [==============================] - 3s 4ms/step - loss: 1.3898 - accuracy: 0.2470 - val_loss: 1.3905 - val_accuracy: 0.2460\n",
      "Epoch 9/100\n",
      "620/630 [============================>.] - ETA: 0s - loss: 1.3907 - accuracy: 0.2457\n",
      "Epoch 9: val_accuracy did not improve from 0.26295\n",
      "630/630 [==============================] - 2s 4ms/step - loss: 1.3907 - accuracy: 0.2458 - val_loss: 1.3916 - val_accuracy: 0.2371\n",
      "Epoch 10/100\n",
      "628/630 [============================>.] - ETA: 0s - loss: 1.3901 - accuracy: 0.2491\n",
      "Epoch 10: val_accuracy did not improve from 0.26295\n",
      "630/630 [==============================] - 2s 4ms/step - loss: 1.3901 - accuracy: 0.2490 - val_loss: 1.3977 - val_accuracy: 0.2384\n",
      "Epoch 11/100\n",
      "627/630 [============================>.] - ETA: 0s - loss: 1.3897 - accuracy: 0.2546\n",
      "Epoch 11: val_accuracy did not improve from 0.26295\n",
      "630/630 [==============================] - 3s 4ms/step - loss: 1.3896 - accuracy: 0.2546 - val_loss: 1.3897 - val_accuracy: 0.2562\n",
      "Epoch 12/100\n",
      "629/630 [============================>.] - ETA: 0s - loss: 1.3900 - accuracy: 0.2465\n",
      "Epoch 12: val_accuracy did not improve from 0.26295\n",
      "630/630 [==============================] - 3s 4ms/step - loss: 1.3899 - accuracy: 0.2466 - val_loss: 1.3924 - val_accuracy: 0.2487\n",
      "Epoch 13/100\n",
      "620/630 [============================>.] - ETA: 0s - loss: 1.3903 - accuracy: 0.2514\n",
      "Epoch 13: val_accuracy did not improve from 0.26295\n",
      "630/630 [==============================] - 3s 4ms/step - loss: 1.3902 - accuracy: 0.2515 - val_loss: 1.3943 - val_accuracy: 0.2527\n",
      "Epoch 14/100\n",
      "627/630 [============================>.] - ETA: 0s - loss: 1.3902 - accuracy: 0.2559\n",
      "Epoch 14: val_accuracy did not improve from 0.26295\n",
      "630/630 [==============================] - 3s 4ms/step - loss: 1.3902 - accuracy: 0.2558 - val_loss: 1.3936 - val_accuracy: 0.2545\n",
      "Epoch 15/100\n",
      "621/630 [============================>.] - ETA: 0s - loss: 1.3901 - accuracy: 0.2491\n",
      "Epoch 15: val_accuracy did not improve from 0.26295\n",
      "630/630 [==============================] - 3s 4ms/step - loss: 1.3902 - accuracy: 0.2493 - val_loss: 1.3883 - val_accuracy: 0.2567\n",
      "Epoch 16/100\n",
      "624/630 [============================>.] - ETA: 0s - loss: 1.3898 - accuracy: 0.2459\n",
      "Epoch 16: val_accuracy did not improve from 0.26295\n",
      "630/630 [==============================] - 3s 4ms/step - loss: 1.3898 - accuracy: 0.2464 - val_loss: 1.3899 - val_accuracy: 0.2545\n",
      "Epoch 17/100\n",
      "618/630 [============================>.] - ETA: 0s - loss: 1.3897 - accuracy: 0.2501\n",
      "Epoch 17: val_accuracy did not improve from 0.26295\n",
      "630/630 [==============================] - 3s 4ms/step - loss: 1.3897 - accuracy: 0.2489 - val_loss: 1.3883 - val_accuracy: 0.2531\n",
      "Epoch 18/100\n",
      "623/630 [============================>.] - ETA: 0s - loss: 1.3897 - accuracy: 0.2474\n",
      "Epoch 18: val_accuracy did not improve from 0.26295\n",
      "630/630 [==============================] - 3s 4ms/step - loss: 1.3897 - accuracy: 0.2479 - val_loss: 1.3890 - val_accuracy: 0.2504\n",
      "Epoch 19/100\n",
      "627/630 [============================>.] - ETA: 0s - loss: 1.3903 - accuracy: 0.2480\n",
      "Epoch 19: val_accuracy did not improve from 0.26295\n",
      "630/630 [==============================] - 2s 4ms/step - loss: 1.3903 - accuracy: 0.2480 - val_loss: 1.3929 - val_accuracy: 0.2379\n",
      "Epoch 20/100\n",
      "629/630 [============================>.] - ETA: 0s - loss: 1.3891 - accuracy: 0.2509\n",
      "Epoch 20: val_accuracy did not improve from 0.26295\n",
      "630/630 [==============================] - 2s 4ms/step - loss: 1.3891 - accuracy: 0.2508 - val_loss: 1.3905 - val_accuracy: 0.2366\n",
      "Epoch 21/100\n",
      "619/630 [============================>.] - ETA: 0s - loss: 1.3900 - accuracy: 0.2507\n",
      "Epoch 21: val_accuracy did not improve from 0.26295\n",
      "630/630 [==============================] - 2s 4ms/step - loss: 1.3900 - accuracy: 0.2502 - val_loss: 1.3874 - val_accuracy: 0.2504\n",
      "Epoch 22/100\n",
      "629/630 [============================>.] - ETA: 0s - loss: 1.3902 - accuracy: 0.2490\n",
      "Epoch 22: val_accuracy did not improve from 0.26295\n",
      "630/630 [==============================] - 3s 4ms/step - loss: 1.3902 - accuracy: 0.2488 - val_loss: 1.3885 - val_accuracy: 0.2446\n",
      "Epoch 23/100\n",
      "625/630 [============================>.] - ETA: 0s - loss: 1.3895 - accuracy: 0.2503\n",
      "Epoch 23: val_accuracy did not improve from 0.26295\n",
      "630/630 [==============================] - 3s 4ms/step - loss: 1.3894 - accuracy: 0.2506 - val_loss: 1.3959 - val_accuracy: 0.2433\n",
      "Epoch 24/100\n",
      "619/630 [============================>.] - ETA: 0s - loss: 1.3897 - accuracy: 0.2496\n",
      "Epoch 24: val_accuracy did not improve from 0.26295\n",
      "630/630 [==============================] - 3s 4ms/step - loss: 1.3897 - accuracy: 0.2497 - val_loss: 1.3903 - val_accuracy: 0.2567\n",
      "Epoch 25/100\n",
      "627/630 [============================>.] - ETA: 0s - loss: 1.3892 - accuracy: 0.2526\n",
      "Epoch 25: val_accuracy improved from 0.26295 to 0.26384, saving model to D:/BMO/Main/savedModels\\0input_model_best.h5\n",
      "630/630 [==============================] - 2s 4ms/step - loss: 1.3892 - accuracy: 0.2525 - val_loss: 1.3911 - val_accuracy: 0.2638\n",
      "Epoch 26/100\n",
      "619/630 [============================>.] - ETA: 0s - loss: 1.3896 - accuracy: 0.2507\n",
      "Epoch 26: val_accuracy did not improve from 0.26384\n",
      "630/630 [==============================] - 3s 4ms/step - loss: 1.3897 - accuracy: 0.2510 - val_loss: 1.3893 - val_accuracy: 0.2607\n",
      "Epoch 27/100\n",
      "626/630 [============================>.] - ETA: 0s - loss: 1.3897 - accuracy: 0.2512\n",
      "Epoch 27: val_accuracy did not improve from 0.26384\n",
      "630/630 [==============================] - 3s 4ms/step - loss: 1.3897 - accuracy: 0.2515 - val_loss: 1.3879 - val_accuracy: 0.2554\n",
      "Epoch 28/100\n",
      "627/630 [============================>.] - ETA: 0s - loss: 1.3897 - accuracy: 0.2498\n",
      "Epoch 28: val_accuracy did not improve from 0.26384\n",
      "630/630 [==============================] - 2s 4ms/step - loss: 1.3897 - accuracy: 0.2498 - val_loss: 1.3929 - val_accuracy: 0.2522\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624/630 [============================>.] - ETA: 0s - loss: 1.3894 - accuracy: 0.2516\n",
      "Epoch 29: val_accuracy did not improve from 0.26384\n",
      "630/630 [==============================] - 2s 4ms/step - loss: 1.3894 - accuracy: 0.2520 - val_loss: 1.3929 - val_accuracy: 0.2500\n",
      "Epoch 30/100\n",
      "624/630 [============================>.] - ETA: 0s - loss: 1.3900 - accuracy: 0.2470\n",
      "Epoch 30: val_accuracy did not improve from 0.26384\n",
      "630/630 [==============================] - 2s 4ms/step - loss: 1.3900 - accuracy: 0.2470 - val_loss: 1.3864 - val_accuracy: 0.2438\n",
      "Epoch 31/100\n",
      "629/630 [============================>.] - ETA: 0s - loss: 1.3892 - accuracy: 0.2534\n",
      "Epoch 31: val_accuracy did not improve from 0.26384\n",
      "630/630 [==============================] - 2s 4ms/step - loss: 1.3892 - accuracy: 0.2534 - val_loss: 1.3894 - val_accuracy: 0.2455\n",
      "Epoch 32/100\n",
      "616/630 [============================>.] - ETA: 0s - loss: 1.3897 - accuracy: 0.2476\n",
      "Epoch 32: val_accuracy did not improve from 0.26384\n",
      "630/630 [==============================] - 2s 4ms/step - loss: 1.3898 - accuracy: 0.2472 - val_loss: 1.3914 - val_accuracy: 0.2406\n",
      "Epoch 33/100\n",
      "629/630 [============================>.] - ETA: 0s - loss: 1.3898 - accuracy: 0.2528\n",
      "Epoch 33: val_accuracy did not improve from 0.26384\n",
      "630/630 [==============================] - 2s 4ms/step - loss: 1.3898 - accuracy: 0.2528 - val_loss: 1.3902 - val_accuracy: 0.2415\n",
      "Epoch 34/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 1.3892 - accuracy: 0.2540\n",
      "Epoch 34: val_accuracy did not improve from 0.26384\n",
      "630/630 [==============================] - 2s 4ms/step - loss: 1.3892 - accuracy: 0.2540 - val_loss: 1.3884 - val_accuracy: 0.2473\n",
      "Epoch 35/100\n",
      "629/630 [============================>.] - ETA: 0s - loss: 1.3893 - accuracy: 0.2499\n",
      "Epoch 35: val_accuracy did not improve from 0.26384\n",
      "630/630 [==============================] - 3s 4ms/step - loss: 1.3893 - accuracy: 0.2501 - val_loss: 1.3919 - val_accuracy: 0.2433\n",
      "Epoch 36/100\n",
      "618/630 [============================>.] - ETA: 0s - loss: 1.3893 - accuracy: 0.2511\n",
      "Epoch 36: val_accuracy did not improve from 0.26384\n",
      "630/630 [==============================] - 3s 4ms/step - loss: 1.3893 - accuracy: 0.2513 - val_loss: 1.3896 - val_accuracy: 0.2424\n",
      "Epoch 37/100\n",
      "629/630 [============================>.] - ETA: 0s - loss: 1.3895 - accuracy: 0.2523\n",
      "Epoch 37: val_accuracy did not improve from 0.26384\n",
      "630/630 [==============================] - 3s 4ms/step - loss: 1.3896 - accuracy: 0.2520 - val_loss: 1.3876 - val_accuracy: 0.2540\n",
      "Epoch 38/100\n",
      "615/630 [============================>.] - ETA: 0s - loss: 1.3894 - accuracy: 0.2518\n",
      "Epoch 38: val_accuracy did not improve from 0.26384\n",
      "630/630 [==============================] - 3s 4ms/step - loss: 1.3895 - accuracy: 0.2515 - val_loss: 1.3871 - val_accuracy: 0.2500\n",
      "Epoch 39/100\n",
      "626/630 [============================>.] - ETA: 0s - loss: 1.3894 - accuracy: 0.2497\n",
      "Epoch 39: val_accuracy did not improve from 0.26384\n",
      "630/630 [==============================] - 2s 4ms/step - loss: 1.3894 - accuracy: 0.2495 - val_loss: 1.3891 - val_accuracy: 0.2540\n",
      "Epoch 40/100\n",
      "620/630 [============================>.] - ETA: 0s - loss: 1.3892 - accuracy: 0.2521\n",
      "Epoch 40: val_accuracy did not improve from 0.26384\n",
      "630/630 [==============================] - 2s 4ms/step - loss: 1.3891 - accuracy: 0.2528 - val_loss: 1.3936 - val_accuracy: 0.2451\n",
      "Epoch 41/100\n",
      "616/630 [============================>.] - ETA: 0s - loss: 1.3894 - accuracy: 0.2471\n",
      "Epoch 41: val_accuracy did not improve from 0.26384\n",
      "630/630 [==============================] - 2s 4ms/step - loss: 1.3895 - accuracy: 0.2470 - val_loss: 1.3899 - val_accuracy: 0.2464\n",
      "Epoch 42/100\n",
      "620/630 [============================>.] - ETA: 0s - loss: 1.3897 - accuracy: 0.2456\n",
      "Epoch 42: val_accuracy did not improve from 0.26384\n",
      "630/630 [==============================] - 2s 4ms/step - loss: 1.3898 - accuracy: 0.2460 - val_loss: 1.3897 - val_accuracy: 0.2567\n",
      "Epoch 43/100\n",
      "622/630 [============================>.] - ETA: 0s - loss: 1.3899 - accuracy: 0.2530\n",
      "Epoch 43: val_accuracy did not improve from 0.26384\n",
      "630/630 [==============================] - 3s 4ms/step - loss: 1.3900 - accuracy: 0.2532 - val_loss: 1.3882 - val_accuracy: 0.2554\n",
      "Epoch 44/100\n",
      "616/630 [============================>.] - ETA: 0s - loss: 1.3892 - accuracy: 0.2518\n",
      "Epoch 44: val_accuracy did not improve from 0.26384\n",
      "630/630 [==============================] - 2s 4ms/step - loss: 1.3892 - accuracy: 0.2524 - val_loss: 1.3911 - val_accuracy: 0.2491\n",
      "Epoch 45/100\n",
      "624/630 [============================>.] - ETA: 0s - loss: 1.3894 - accuracy: 0.2515\n",
      "Epoch 45: val_accuracy did not improve from 0.26384\n",
      "630/630 [==============================] - 2s 4ms/step - loss: 1.3894 - accuracy: 0.2518 - val_loss: 1.3906 - val_accuracy: 0.2473\n",
      "Epoch 46/100\n",
      "628/630 [============================>.] - ETA: 0s - loss: 1.3893 - accuracy: 0.2486\n",
      "Epoch 46: val_accuracy did not improve from 0.26384\n",
      "630/630 [==============================] - 3s 4ms/step - loss: 1.3894 - accuracy: 0.2486 - val_loss: 1.3910 - val_accuracy: 0.2571\n",
      "Epoch 47/100\n",
      "618/630 [============================>.] - ETA: 0s - loss: 1.3889 - accuracy: 0.2536\n",
      "Epoch 47: val_accuracy did not improve from 0.26384\n",
      "630/630 [==============================] - 3s 4ms/step - loss: 1.3889 - accuracy: 0.2532 - val_loss: 1.3880 - val_accuracy: 0.2531\n",
      "Epoch 48/100\n",
      "626/630 [============================>.] - ETA: 0s - loss: 1.3889 - accuracy: 0.2560\n",
      "Epoch 48: val_accuracy did not improve from 0.26384\n",
      "630/630 [==============================] - 3s 4ms/step - loss: 1.3889 - accuracy: 0.2559 - val_loss: 1.3887 - val_accuracy: 0.2589\n",
      "Epoch 49/100\n",
      "617/630 [============================>.] - ETA: 0s - loss: 1.3896 - accuracy: 0.2482\n",
      "Epoch 49: val_accuracy did not improve from 0.26384\n",
      "630/630 [==============================] - 2s 4ms/step - loss: 1.3896 - accuracy: 0.2485 - val_loss: 1.3892 - val_accuracy: 0.2478\n",
      "Epoch 50/100\n",
      "628/630 [============================>.] - ETA: 0s - loss: 1.3891 - accuracy: 0.2488\n",
      "Epoch 50: val_accuracy did not improve from 0.26384\n",
      "630/630 [==============================] - 3s 4ms/step - loss: 1.3892 - accuracy: 0.2487 - val_loss: 1.3903 - val_accuracy: 0.2464\n",
      "Epoch 50: early stopping\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 1.3932 - accuracy: 0.2402\n",
      "175/175 [==============================] - 1s 2ms/step\n",
      "[0.33621062 0.         0.26224121 0.16158684]\n",
      "[0.57111437 0.         0.27921624 0.12361214]\n",
      "..........Training set..........\n",
      "(20160, 128, 1)\n",
      "(20160,)\n",
      "..........Validation set..........\n",
      "(2240, 128, 1)\n",
      "(2240,)\n",
      "..........Testing set..........\n",
      "(5600, 128, 1)\n",
      "(5600,)\n",
      "Epoch 1/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 1.2939 - accuracy: 0.4033\n",
      "Epoch 1: val_accuracy improved from -inf to 0.46027, saving model to D:/BMO/Main/savedModels\\0input_model_best.h5\n",
      "630/630 [==============================] - 10s 12ms/step - loss: 1.2939 - accuracy: 0.4033 - val_loss: 1.1420 - val_accuracy: 0.4603\n",
      "Epoch 2/100\n",
      "627/630 [============================>.] - ETA: 0s - loss: 1.1255 - accuracy: 0.4728\n",
      "Epoch 2: val_accuracy did not improve from 0.46027\n",
      "630/630 [==============================] - 7s 11ms/step - loss: 1.1254 - accuracy: 0.4729 - val_loss: 1.2088 - val_accuracy: 0.4455\n",
      "Epoch 3/100\n",
      "629/630 [============================>.] - ETA: 0s - loss: 1.0820 - accuracy: 0.4993\n",
      "Epoch 3: val_accuracy improved from 0.46027 to 0.51250, saving model to D:/BMO/Main/savedModels\\0input_model_best.h5\n",
      "630/630 [==============================] - 7s 12ms/step - loss: 1.0818 - accuracy: 0.4992 - val_loss: 1.0429 - val_accuracy: 0.5125\n",
      "Epoch 4/100\n",
      "628/630 [============================>.] - ETA: 0s - loss: 1.0551 - accuracy: 0.5183\n",
      "Epoch 4: val_accuracy improved from 0.51250 to 0.52143, saving model to D:/BMO/Main/savedModels\\0input_model_best.h5\n",
      "630/630 [==============================] - 7s 12ms/step - loss: 1.0552 - accuracy: 0.5182 - val_loss: 1.0345 - val_accuracy: 0.5214\n",
      "Epoch 5/100\n",
      "626/630 [============================>.] - ETA: 0s - loss: 1.0453 - accuracy: 0.5225\n",
      "Epoch 5: val_accuracy did not improve from 0.52143\n",
      "630/630 [==============================] - 7s 11ms/step - loss: 1.0449 - accuracy: 0.5231 - val_loss: 1.0552 - val_accuracy: 0.5112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100\n",
      "627/630 [============================>.] - ETA: 0s - loss: 1.0323 - accuracy: 0.5313\n",
      "Epoch 6: val_accuracy improved from 0.52143 to 0.52455, saving model to D:/BMO/Main/savedModels\\0input_model_best.h5\n",
      "630/630 [==============================] - 7s 11ms/step - loss: 1.0314 - accuracy: 0.5317 - val_loss: 1.0277 - val_accuracy: 0.5246\n",
      "Epoch 7/100\n",
      "626/630 [============================>.] - ETA: 0s - loss: 1.0284 - accuracy: 0.5347\n",
      "Epoch 7: val_accuracy improved from 0.52455 to 0.52946, saving model to D:/BMO/Main/savedModels\\0input_model_best.h5\n",
      "630/630 [==============================] - 7s 11ms/step - loss: 1.0285 - accuracy: 0.5349 - val_loss: 1.0230 - val_accuracy: 0.5295\n",
      "Epoch 8/100\n",
      "626/630 [============================>.] - ETA: 0s - loss: 1.0181 - accuracy: 0.5362\n",
      "Epoch 8: val_accuracy did not improve from 0.52946\n",
      "630/630 [==============================] - 7s 12ms/step - loss: 1.0183 - accuracy: 0.5361 - val_loss: 1.0468 - val_accuracy: 0.5214\n",
      "Epoch 9/100\n",
      "625/630 [============================>.] - ETA: 0s - loss: 1.0113 - accuracy: 0.5413\n",
      "Epoch 9: val_accuracy improved from 0.52946 to 0.53348, saving model to D:/BMO/Main/savedModels\\0input_model_best.h5\n",
      "630/630 [==============================] - 7s 11ms/step - loss: 1.0116 - accuracy: 0.5416 - val_loss: 1.0105 - val_accuracy: 0.5335\n",
      "Epoch 10/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 1.0145 - accuracy: 0.5394\n",
      "Epoch 10: val_accuracy did not improve from 0.53348\n",
      "630/630 [==============================] - 7s 11ms/step - loss: 1.0145 - accuracy: 0.5394 - val_loss: 1.0393 - val_accuracy: 0.5259\n",
      "Epoch 11/100\n",
      "626/630 [============================>.] - ETA: 0s - loss: 1.0075 - accuracy: 0.5421\n",
      "Epoch 11: val_accuracy improved from 0.53348 to 0.54107, saving model to D:/BMO/Main/savedModels\\0input_model_best.h5\n",
      "630/630 [==============================] - 7s 11ms/step - loss: 1.0081 - accuracy: 0.5418 - val_loss: 1.0262 - val_accuracy: 0.5411\n",
      "Epoch 12/100\n",
      "626/630 [============================>.] - ETA: 0s - loss: 1.0042 - accuracy: 0.5463\n",
      "Epoch 12: val_accuracy did not improve from 0.54107\n",
      "630/630 [==============================] - 7s 12ms/step - loss: 1.0043 - accuracy: 0.5465 - val_loss: 1.0527 - val_accuracy: 0.5237\n",
      "Epoch 13/100\n",
      "626/630 [============================>.] - ETA: 0s - loss: 1.0021 - accuracy: 0.5484\n",
      "Epoch 13: val_accuracy did not improve from 0.54107\n",
      "630/630 [==============================] - 7s 11ms/step - loss: 1.0019 - accuracy: 0.5488 - val_loss: 1.0033 - val_accuracy: 0.5357\n",
      "Epoch 14/100\n",
      "629/630 [============================>.] - ETA: 0s - loss: 0.9982 - accuracy: 0.5502\n",
      "Epoch 14: val_accuracy did not improve from 0.54107\n",
      "630/630 [==============================] - 7s 11ms/step - loss: 0.9981 - accuracy: 0.5503 - val_loss: 1.0316 - val_accuracy: 0.5299\n",
      "Epoch 15/100\n",
      "628/630 [============================>.] - ETA: 0s - loss: 0.9970 - accuracy: 0.5513\n",
      "Epoch 15: val_accuracy did not improve from 0.54107\n",
      "630/630 [==============================] - 7s 11ms/step - loss: 0.9971 - accuracy: 0.5511 - val_loss: 1.0044 - val_accuracy: 0.5335\n",
      "Epoch 16/100\n",
      "626/630 [============================>.] - ETA: 0s - loss: 0.9957 - accuracy: 0.5502\n",
      "Epoch 16: val_accuracy did not improve from 0.54107\n",
      "630/630 [==============================] - 7s 11ms/step - loss: 0.9954 - accuracy: 0.5500 - val_loss: 1.0061 - val_accuracy: 0.5335\n",
      "Epoch 17/100\n",
      "628/630 [============================>.] - ETA: 0s - loss: 0.9901 - accuracy: 0.5529\n",
      "Epoch 17: val_accuracy did not improve from 0.54107\n",
      "630/630 [==============================] - 7s 11ms/step - loss: 0.9898 - accuracy: 0.5529 - val_loss: 1.0209 - val_accuracy: 0.5295\n",
      "Epoch 18/100\n",
      "628/630 [============================>.] - ETA: 0s - loss: 0.9921 - accuracy: 0.5517\n",
      "Epoch 18: val_accuracy improved from 0.54107 to 0.54420, saving model to D:/BMO/Main/savedModels\\0input_model_best.h5\n",
      "630/630 [==============================] - 7s 11ms/step - loss: 0.9921 - accuracy: 0.5516 - val_loss: 1.0004 - val_accuracy: 0.5442\n",
      "Epoch 19/100\n",
      "627/630 [============================>.] - ETA: 0s - loss: 0.9889 - accuracy: 0.5540\n",
      "Epoch 19: val_accuracy did not improve from 0.54420\n",
      "630/630 [==============================] - 7s 11ms/step - loss: 0.9890 - accuracy: 0.5542 - val_loss: 1.0132 - val_accuracy: 0.5379\n",
      "Epoch 20/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.9885 - accuracy: 0.5568\n",
      "Epoch 20: val_accuracy did not improve from 0.54420\n",
      "630/630 [==============================] - 7s 11ms/step - loss: 0.9885 - accuracy: 0.5568 - val_loss: 1.0235 - val_accuracy: 0.5339\n",
      "Epoch 21/100\n",
      "627/630 [============================>.] - ETA: 0s - loss: 0.9842 - accuracy: 0.5585\n",
      "Epoch 21: val_accuracy did not improve from 0.54420\n",
      "630/630 [==============================] - 7s 11ms/step - loss: 0.9844 - accuracy: 0.5583 - val_loss: 1.0320 - val_accuracy: 0.5402\n",
      "Epoch 22/100\n",
      "627/630 [============================>.] - ETA: 0s - loss: 0.9857 - accuracy: 0.5584\n",
      "Epoch 22: val_accuracy did not improve from 0.54420\n",
      "630/630 [==============================] - 7s 11ms/step - loss: 0.9855 - accuracy: 0.5585 - val_loss: 0.9963 - val_accuracy: 0.5442\n",
      "Epoch 23/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.9831 - accuracy: 0.5593\n",
      "Epoch 23: val_accuracy improved from 0.54420 to 0.54554, saving model to D:/BMO/Main/savedModels\\0input_model_best.h5\n",
      "630/630 [==============================] - 7s 11ms/step - loss: 0.9831 - accuracy: 0.5593 - val_loss: 1.0091 - val_accuracy: 0.5455\n",
      "Epoch 24/100\n",
      "627/630 [============================>.] - ETA: 0s - loss: 0.9815 - accuracy: 0.5579\n",
      "Epoch 24: val_accuracy did not improve from 0.54554\n",
      "630/630 [==============================] - 7s 11ms/step - loss: 0.9810 - accuracy: 0.5581 - val_loss: 1.0445 - val_accuracy: 0.5317\n",
      "Epoch 25/100\n",
      "628/630 [============================>.] - ETA: 0s - loss: 0.9803 - accuracy: 0.5576\n",
      "Epoch 25: val_accuracy improved from 0.54554 to 0.54643, saving model to D:/BMO/Main/savedModels\\0input_model_best.h5\n",
      "630/630 [==============================] - 7s 11ms/step - loss: 0.9805 - accuracy: 0.5575 - val_loss: 1.0140 - val_accuracy: 0.5464\n",
      "Epoch 26/100\n",
      "627/630 [============================>.] - ETA: 0s - loss: 0.9785 - accuracy: 0.5585\n",
      "Epoch 26: val_accuracy did not improve from 0.54643\n",
      "630/630 [==============================] - 7s 11ms/step - loss: 0.9782 - accuracy: 0.5587 - val_loss: 1.0290 - val_accuracy: 0.5406\n",
      "Epoch 27/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.9775 - accuracy: 0.5622\n",
      "Epoch 27: val_accuracy improved from 0.54643 to 0.54777, saving model to D:/BMO/Main/savedModels\\0input_model_best.h5\n",
      "630/630 [==============================] - 7s 11ms/step - loss: 0.9775 - accuracy: 0.5622 - val_loss: 0.9883 - val_accuracy: 0.5478\n",
      "Epoch 28/100\n",
      "627/630 [============================>.] - ETA: 0s - loss: 0.9798 - accuracy: 0.5586\n",
      "Epoch 28: val_accuracy did not improve from 0.54777\n",
      "630/630 [==============================] - 7s 11ms/step - loss: 0.9801 - accuracy: 0.5584 - val_loss: 1.0089 - val_accuracy: 0.5321\n",
      "Epoch 29/100\n",
      "629/630 [============================>.] - ETA: 0s - loss: 0.9768 - accuracy: 0.5633\n",
      "Epoch 29: val_accuracy did not improve from 0.54777\n",
      "630/630 [==============================] - 7s 11ms/step - loss: 0.9768 - accuracy: 0.5633 - val_loss: 1.0032 - val_accuracy: 0.5344\n",
      "Epoch 30/100\n",
      "628/630 [============================>.] - ETA: 0s - loss: 0.9753 - accuracy: 0.5601\n",
      "Epoch 30: val_accuracy did not improve from 0.54777\n",
      "630/630 [==============================] - 7s 11ms/step - loss: 0.9753 - accuracy: 0.5602 - val_loss: 0.9894 - val_accuracy: 0.5433\n",
      "Epoch 31/100\n",
      "628/630 [============================>.] - ETA: 0s - loss: 0.9788 - accuracy: 0.5588\n",
      "Epoch 31: val_accuracy improved from 0.54777 to 0.55045, saving model to D:/BMO/Main/savedModels\\0input_model_best.h5\n",
      "630/630 [==============================] - 7s 11ms/step - loss: 0.9784 - accuracy: 0.5590 - val_loss: 0.9895 - val_accuracy: 0.5504\n",
      "Epoch 32/100\n",
      "628/630 [============================>.] - ETA: 0s - loss: 0.9699 - accuracy: 0.5661\n",
      "Epoch 32: val_accuracy did not improve from 0.55045\n",
      "630/630 [==============================] - 7s 11ms/step - loss: 0.9701 - accuracy: 0.5660 - val_loss: 1.0061 - val_accuracy: 0.5366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.9686 - accuracy: 0.5634\n",
      "Epoch 33: val_accuracy did not improve from 0.55045\n",
      "630/630 [==============================] - 7s 11ms/step - loss: 0.9686 - accuracy: 0.5634 - val_loss: 0.9902 - val_accuracy: 0.5496\n",
      "Epoch 34/100\n",
      "628/630 [============================>.] - ETA: 0s - loss: 0.9718 - accuracy: 0.5628\n",
      "Epoch 34: val_accuracy did not improve from 0.55045\n",
      "630/630 [==============================] - 7s 11ms/step - loss: 0.9719 - accuracy: 0.5627 - val_loss: 1.0077 - val_accuracy: 0.5424\n",
      "Epoch 35/100\n",
      "628/630 [============================>.] - ETA: 0s - loss: 0.9696 - accuracy: 0.5654\n",
      "Epoch 35: val_accuracy did not improve from 0.55045\n",
      "630/630 [==============================] - 7s 11ms/step - loss: 0.9696 - accuracy: 0.5656 - val_loss: 1.0000 - val_accuracy: 0.5424\n",
      "Epoch 36/100\n",
      "627/630 [============================>.] - ETA: 0s - loss: 0.9680 - accuracy: 0.5668\n",
      "Epoch 36: val_accuracy did not improve from 0.55045\n",
      "630/630 [==============================] - 7s 11ms/step - loss: 0.9676 - accuracy: 0.5669 - val_loss: 0.9978 - val_accuracy: 0.5464\n",
      "Epoch 37/100\n",
      "626/630 [============================>.] - ETA: 0s - loss: 0.9712 - accuracy: 0.5645\n",
      "Epoch 37: val_accuracy did not improve from 0.55045\n",
      "630/630 [==============================] - 7s 11ms/step - loss: 0.9715 - accuracy: 0.5645 - val_loss: 1.0196 - val_accuracy: 0.5375\n",
      "Epoch 38/100\n",
      "626/630 [============================>.] - ETA: 0s - loss: 0.9679 - accuracy: 0.5661\n",
      "Epoch 38: val_accuracy did not improve from 0.55045\n",
      "630/630 [==============================] - 7s 12ms/step - loss: 0.9684 - accuracy: 0.5662 - val_loss: 0.9928 - val_accuracy: 0.5469\n",
      "Epoch 39/100\n",
      "625/630 [============================>.] - ETA: 0s - loss: 0.9660 - accuracy: 0.5659\n",
      "Epoch 39: val_accuracy did not improve from 0.55045\n",
      "630/630 [==============================] - 7s 11ms/step - loss: 0.9663 - accuracy: 0.5659 - val_loss: 0.9917 - val_accuracy: 0.5442\n",
      "Epoch 40/100\n",
      "629/630 [============================>.] - ETA: 0s - loss: 0.9689 - accuracy: 0.5679\n",
      "Epoch 40: val_accuracy did not improve from 0.55045\n",
      "630/630 [==============================] - 7s 11ms/step - loss: 0.9685 - accuracy: 0.5681 - val_loss: 1.0088 - val_accuracy: 0.5460\n",
      "Epoch 41/100\n",
      "626/630 [============================>.] - ETA: 0s - loss: 0.9680 - accuracy: 0.5658\n",
      "Epoch 41: val_accuracy improved from 0.55045 to 0.55268, saving model to D:/BMO/Main/savedModels\\0input_model_best.h5\n",
      "630/630 [==============================] - 7s 11ms/step - loss: 0.9684 - accuracy: 0.5655 - val_loss: 0.9915 - val_accuracy: 0.5527\n",
      "Epoch 42/100\n",
      "626/630 [============================>.] - ETA: 0s - loss: 0.9663 - accuracy: 0.5659\n",
      "Epoch 42: val_accuracy did not improve from 0.55268\n",
      "630/630 [==============================] - 7s 11ms/step - loss: 0.9662 - accuracy: 0.5660 - val_loss: 1.0321 - val_accuracy: 0.5321\n",
      "Epoch 43/100\n",
      "627/630 [============================>.] - ETA: 0s - loss: 0.9669 - accuracy: 0.5657\n",
      "Epoch 43: val_accuracy did not improve from 0.55268\n",
      "630/630 [==============================] - 7s 11ms/step - loss: 0.9672 - accuracy: 0.5657 - val_loss: 0.9923 - val_accuracy: 0.5353\n",
      "Epoch 44/100\n",
      "628/630 [============================>.] - ETA: 0s - loss: 0.9630 - accuracy: 0.5690\n",
      "Epoch 44: val_accuracy did not improve from 0.55268\n",
      "630/630 [==============================] - 7s 11ms/step - loss: 0.9629 - accuracy: 0.5690 - val_loss: 1.0015 - val_accuracy: 0.5437\n",
      "Epoch 45/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.9682 - accuracy: 0.5665\n",
      "Epoch 45: val_accuracy did not improve from 0.55268\n",
      "630/630 [==============================] - 7s 11ms/step - loss: 0.9682 - accuracy: 0.5665 - val_loss: 1.0113 - val_accuracy: 0.5388\n",
      "Epoch 46/100\n",
      "627/630 [============================>.] - ETA: 0s - loss: 0.9642 - accuracy: 0.5657\n",
      "Epoch 46: val_accuracy did not improve from 0.55268\n",
      "630/630 [==============================] - 7s 11ms/step - loss: 0.9636 - accuracy: 0.5660 - val_loss: 1.0136 - val_accuracy: 0.5384\n",
      "Epoch 47/100\n",
      "627/630 [============================>.] - ETA: 0s - loss: 0.9645 - accuracy: 0.5653\n",
      "Epoch 47: val_accuracy did not improve from 0.55268\n",
      "630/630 [==============================] - 7s 11ms/step - loss: 0.9645 - accuracy: 0.5651 - val_loss: 0.9982 - val_accuracy: 0.5402\n",
      "Epoch 47: early stopping\n",
      "Saved model to disk\n",
      "Confusion Matrix when Symbol Length  128\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 0.9873 - accuracy: 0.5484\n",
      "175/175 [==============================] - 2s 6ms/step\n",
      "[0.44913628 0.42027921 0.79864636 0.51481018]\n",
      "[0.51466276 0.39285714 0.82575227 0.45669874]\n",
      "..........Training set..........\n",
      "(20160, 1024, 1)\n",
      "(20160,)\n",
      "..........Validation set..........\n",
      "(2240, 1024, 1)\n",
      "(2240,)\n",
      "..........Testing set..........\n",
      "(5600, 1024, 1)\n",
      "(5600,)\n",
      "Epoch 1/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 1.2464 - accuracy: 0.5702\n",
      "Epoch 1: val_accuracy improved from -inf to 0.70625, saving model to D:/BMO/Main/savedModels\\0input_model_best.h5\n",
      "630/630 [==============================] - 32s 48ms/step - loss: 1.2464 - accuracy: 0.5702 - val_loss: 0.6869 - val_accuracy: 0.7063\n",
      "Epoch 2/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.6127 - accuracy: 0.7361\n",
      "Epoch 2: val_accuracy improved from 0.70625 to 0.72857, saving model to D:/BMO/Main/savedModels\\0input_model_best.h5\n",
      "630/630 [==============================] - 29s 47ms/step - loss: 0.6127 - accuracy: 0.7361 - val_loss: 0.6345 - val_accuracy: 0.7286\n",
      "Epoch 3/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.5192 - accuracy: 0.7803\n",
      "Epoch 3: val_accuracy improved from 0.72857 to 0.79643, saving model to D:/BMO/Main/savedModels\\0input_model_best.h5\n",
      "630/630 [==============================] - 30s 47ms/step - loss: 0.5192 - accuracy: 0.7803 - val_loss: 0.4830 - val_accuracy: 0.7964\n",
      "Epoch 4/100\n",
      "629/630 [============================>.] - ETA: 0s - loss: 0.4684 - accuracy: 0.8052\n",
      "Epoch 4: val_accuracy did not improve from 0.79643\n",
      "630/630 [==============================] - 30s 47ms/step - loss: 0.4686 - accuracy: 0.8051 - val_loss: 0.5522 - val_accuracy: 0.7647\n",
      "Epoch 5/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.4552 - accuracy: 0.8091\n",
      "Epoch 5: val_accuracy did not improve from 0.79643\n",
      "630/630 [==============================] - 30s 48ms/step - loss: 0.4552 - accuracy: 0.8091 - val_loss: 0.5598 - val_accuracy: 0.7696\n",
      "Epoch 6/100\n",
      "629/630 [============================>.] - ETA: 0s - loss: 0.4303 - accuracy: 0.8173\n",
      "Epoch 6: val_accuracy improved from 0.79643 to 0.81205, saving model to D:/BMO/Main/savedModels\\0input_model_best.h5\n",
      "630/630 [==============================] - 30s 48ms/step - loss: 0.4302 - accuracy: 0.8174 - val_loss: 0.4465 - val_accuracy: 0.8121\n",
      "Epoch 7/100\n",
      "629/630 [============================>.] - ETA: 0s - loss: 0.4165 - accuracy: 0.8287\n",
      "Epoch 7: val_accuracy improved from 0.81205 to 0.81250, saving model to D:/BMO/Main/savedModels\\0input_model_best.h5\n",
      "630/630 [==============================] - 30s 47ms/step - loss: 0.4166 - accuracy: 0.8287 - val_loss: 0.4528 - val_accuracy: 0.8125\n",
      "Epoch 8/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.4011 - accuracy: 0.8340\n",
      "Epoch 8: val_accuracy did not improve from 0.81250\n",
      "630/630 [==============================] - 30s 48ms/step - loss: 0.4011 - accuracy: 0.8340 - val_loss: 0.5033 - val_accuracy: 0.7969\n",
      "Epoch 9/100\n",
      "629/630 [============================>.] - ETA: 0s - loss: 0.4093 - accuracy: 0.8296\n",
      "Epoch 9: val_accuracy improved from 0.81250 to 0.81920, saving model to D:/BMO/Main/savedModels\\0input_model_best.h5\n",
      "630/630 [==============================] - 30s 48ms/step - loss: 0.4095 - accuracy: 0.8296 - val_loss: 0.4255 - val_accuracy: 0.8192\n",
      "Epoch 10/100\n",
      "629/630 [============================>.] - ETA: 0s - loss: 0.3937 - accuracy: 0.8378\n",
      "Epoch 10: val_accuracy improved from 0.81920 to 0.81964, saving model to D:/BMO/Main/savedModels\\0input_model_best.h5\n",
      "630/630 [==============================] - 30s 48ms/step - loss: 0.3939 - accuracy: 0.8377 - val_loss: 0.4242 - val_accuracy: 0.8196\n",
      "Epoch 11/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.3762 - accuracy: 0.8466\n",
      "Epoch 11: val_accuracy improved from 0.81964 to 0.82098, saving model to D:/BMO/Main/savedModels\\0input_model_best.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 30s 47ms/step - loss: 0.3762 - accuracy: 0.8466 - val_loss: 0.4372 - val_accuracy: 0.8210\n",
      "Epoch 12/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.3942 - accuracy: 0.8376\n",
      "Epoch 12: val_accuracy did not improve from 0.82098\n",
      "630/630 [==============================] - 33s 52ms/step - loss: 0.3942 - accuracy: 0.8376 - val_loss: 0.4462 - val_accuracy: 0.8134\n",
      "Epoch 13/100\n",
      "629/630 [============================>.] - ETA: 0s - loss: 0.3781 - accuracy: 0.8465\n",
      "Epoch 13: val_accuracy did not improve from 0.82098\n",
      "630/630 [==============================] - 31s 50ms/step - loss: 0.3780 - accuracy: 0.8466 - val_loss: 0.4581 - val_accuracy: 0.8205\n",
      "Epoch 14/100\n",
      "629/630 [============================>.] - ETA: 0s - loss: 0.3548 - accuracy: 0.8556\n",
      "Epoch 14: val_accuracy improved from 0.82098 to 0.83438, saving model to D:/BMO/Main/savedModels\\0input_model_best.h5\n",
      "630/630 [==============================] - 29s 47ms/step - loss: 0.3549 - accuracy: 0.8556 - val_loss: 0.4090 - val_accuracy: 0.8344\n",
      "Epoch 15/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.3454 - accuracy: 0.8584\n",
      "Epoch 15: val_accuracy did not improve from 0.83438\n",
      "630/630 [==============================] - 29s 47ms/step - loss: 0.3454 - accuracy: 0.8584 - val_loss: 0.5594 - val_accuracy: 0.7906\n",
      "Epoch 16/100\n",
      "629/630 [============================>.] - ETA: 0s - loss: 0.3585 - accuracy: 0.8547\n",
      "Epoch 16: val_accuracy did not improve from 0.83438\n",
      "630/630 [==============================] - 29s 46ms/step - loss: 0.3592 - accuracy: 0.8544 - val_loss: 0.4528 - val_accuracy: 0.8170\n",
      "Epoch 17/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.3630 - accuracy: 0.8499\n",
      "Epoch 17: val_accuracy did not improve from 0.83438\n",
      "630/630 [==============================] - 29s 47ms/step - loss: 0.3630 - accuracy: 0.8499 - val_loss: 0.4789 - val_accuracy: 0.8116\n",
      "Epoch 18/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.3596 - accuracy: 0.8531\n",
      "Epoch 18: val_accuracy did not improve from 0.83438\n",
      "630/630 [==============================] - 29s 46ms/step - loss: 0.3596 - accuracy: 0.8531 - val_loss: 0.4759 - val_accuracy: 0.8040\n",
      "Epoch 19/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.3477 - accuracy: 0.8598\n",
      "Epoch 19: val_accuracy did not improve from 0.83438\n",
      "630/630 [==============================] - 29s 47ms/step - loss: 0.3477 - accuracy: 0.8598 - val_loss: 0.7374 - val_accuracy: 0.7362\n",
      "Epoch 20/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.3375 - accuracy: 0.8612\n",
      "Epoch 20: val_accuracy did not improve from 0.83438\n",
      "630/630 [==============================] - 32s 51ms/step - loss: 0.3375 - accuracy: 0.8612 - val_loss: 0.4133 - val_accuracy: 0.8295\n",
      "Epoch 21/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.3395 - accuracy: 0.8624\n",
      "Epoch 21: val_accuracy did not improve from 0.83438\n",
      "630/630 [==============================] - 31s 49ms/step - loss: 0.3395 - accuracy: 0.8624 - val_loss: 0.4414 - val_accuracy: 0.8192\n",
      "Epoch 22/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.3499 - accuracy: 0.8570\n",
      "Epoch 22: val_accuracy did not improve from 0.83438\n",
      "630/630 [==============================] - 30s 48ms/step - loss: 0.3499 - accuracy: 0.8570 - val_loss: 0.4527 - val_accuracy: 0.8241\n",
      "Epoch 23/100\n",
      "629/630 [============================>.] - ETA: 0s - loss: 0.3378 - accuracy: 0.8635\n",
      "Epoch 23: val_accuracy did not improve from 0.83438\n",
      "630/630 [==============================] - 31s 48ms/step - loss: 0.3379 - accuracy: 0.8635 - val_loss: 0.4430 - val_accuracy: 0.8277\n",
      "Epoch 24/100\n",
      "629/630 [============================>.] - ETA: 0s - loss: 0.3468 - accuracy: 0.8575\n",
      "Epoch 24: val_accuracy did not improve from 0.83438\n",
      "630/630 [==============================] - 30s 48ms/step - loss: 0.3473 - accuracy: 0.8573 - val_loss: 0.4542 - val_accuracy: 0.8313\n",
      "Epoch 25/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.3329 - accuracy: 0.8648\n",
      "Epoch 25: val_accuracy did not improve from 0.83438\n",
      "630/630 [==============================] - 31s 48ms/step - loss: 0.3329 - accuracy: 0.8648 - val_loss: 0.4172 - val_accuracy: 0.8304\n",
      "Epoch 26/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.3368 - accuracy: 0.8660\n",
      "Epoch 26: val_accuracy did not improve from 0.83438\n",
      "630/630 [==============================] - 30s 48ms/step - loss: 0.3368 - accuracy: 0.8660 - val_loss: 0.5225 - val_accuracy: 0.8107\n",
      "Epoch 27/100\n",
      "629/630 [============================>.] - ETA: 0s - loss: 0.3338 - accuracy: 0.8650\n",
      "Epoch 27: val_accuracy did not improve from 0.83438\n",
      "630/630 [==============================] - 31s 49ms/step - loss: 0.3338 - accuracy: 0.8650 - val_loss: 0.5697 - val_accuracy: 0.7937\n",
      "Epoch 28/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.3277 - accuracy: 0.8653\n",
      "Epoch 28: val_accuracy did not improve from 0.83438\n",
      "630/630 [==============================] - 30s 48ms/step - loss: 0.3277 - accuracy: 0.8653 - val_loss: 0.5116 - val_accuracy: 0.8094\n",
      "Epoch 29/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.3444 - accuracy: 0.8614\n",
      "Epoch 29: val_accuracy did not improve from 0.83438\n",
      "630/630 [==============================] - 31s 49ms/step - loss: 0.3444 - accuracy: 0.8614 - val_loss: 0.4613 - val_accuracy: 0.8196\n",
      "Epoch 30/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.3329 - accuracy: 0.8654\n",
      "Epoch 30: val_accuracy did not improve from 0.83438\n",
      "630/630 [==============================] - 29s 47ms/step - loss: 0.3329 - accuracy: 0.8654 - val_loss: 0.4478 - val_accuracy: 0.8286\n",
      "Epoch 31/100\n",
      "629/630 [============================>.] - ETA: 0s - loss: 0.3307 - accuracy: 0.8666\n",
      "Epoch 31: val_accuracy did not improve from 0.83438\n",
      "630/630 [==============================] - 29s 47ms/step - loss: 0.3308 - accuracy: 0.8665 - val_loss: 0.5953 - val_accuracy: 0.7942\n",
      "Epoch 32/100\n",
      "629/630 [============================>.] - ETA: 0s - loss: 0.3304 - accuracy: 0.8660\n",
      "Epoch 32: val_accuracy did not improve from 0.83438\n",
      "630/630 [==============================] - 29s 46ms/step - loss: 0.3304 - accuracy: 0.8661 - val_loss: 0.4731 - val_accuracy: 0.8228\n",
      "Epoch 33/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.3180 - accuracy: 0.8733\n",
      "Epoch 33: val_accuracy did not improve from 0.83438\n",
      "630/630 [==============================] - 30s 47ms/step - loss: 0.3180 - accuracy: 0.8733 - val_loss: 0.7079 - val_accuracy: 0.7464\n",
      "Epoch 34/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.3230 - accuracy: 0.8694\n",
      "Epoch 34: val_accuracy did not improve from 0.83438\n",
      "630/630 [==============================] - 29s 46ms/step - loss: 0.3230 - accuracy: 0.8694 - val_loss: 1.1091 - val_accuracy: 0.7085\n",
      "Epoch 34: early stopping\n",
      "175/175 [==============================] - 2s 13ms/step - loss: 1.0512 - accuracy: 0.7163\n",
      "175/175 [==============================] - 2s 13ms/step\n",
      "[0.41582042 0.69716088 0.97712073 0.68319838]\n",
      "[0.28519062 0.60714286 0.97130861 0.99925981]\n",
      "..........Training set..........\n",
      "(20160, 1800, 1)\n",
      "(20160,)\n",
      "..........Validation set..........\n",
      "(2240, 1800, 1)\n",
      "(2240,)\n",
      "..........Testing set..........\n",
      "(5600, 1800, 1)\n",
      "(5600,)\n",
      "Epoch 1/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 1.2211 - accuracy: 0.6423\n",
      "Epoch 1: val_accuracy improved from -inf to 0.74866, saving model to D:/BMO/Main/savedModels\\0input_model_best.h5\n",
      "630/630 [==============================] - 46s 70ms/step - loss: 1.2211 - accuracy: 0.6423 - val_loss: 0.5974 - val_accuracy: 0.7487\n",
      "Epoch 2/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.4926 - accuracy: 0.7930\n",
      "Epoch 2: val_accuracy improved from 0.74866 to 0.76652, saving model to D:/BMO/Main/savedModels\\0input_model_best.h5\n",
      "630/630 [==============================] - 44s 70ms/step - loss: 0.4926 - accuracy: 0.7930 - val_loss: 0.5434 - val_accuracy: 0.7665\n",
      "Epoch 3/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.4347 - accuracy: 0.8208\n",
      "Epoch 3: val_accuracy improved from 0.76652 to 0.77545, saving model to D:/BMO/Main/savedModels\\0input_model_best.h5\n",
      "630/630 [==============================] - 44s 69ms/step - loss: 0.4347 - accuracy: 0.8208 - val_loss: 0.5597 - val_accuracy: 0.7754\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - ETA: 0s - loss: 0.3998 - accuracy: 0.8388\n",
      "Epoch 4: val_accuracy improved from 0.77545 to 0.82946, saving model to D:/BMO/Main/savedModels\\0input_model_best.h5\n",
      "630/630 [==============================] - 47s 74ms/step - loss: 0.3998 - accuracy: 0.8388 - val_loss: 0.4106 - val_accuracy: 0.8295\n",
      "Epoch 5/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.3653 - accuracy: 0.8516\n",
      "Epoch 5: val_accuracy did not improve from 0.82946\n",
      "630/630 [==============================] - 46s 73ms/step - loss: 0.3653 - accuracy: 0.8516 - val_loss: 0.4763 - val_accuracy: 0.8116\n",
      "Epoch 6/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.3515 - accuracy: 0.8616\n",
      "Epoch 6: val_accuracy did not improve from 0.82946\n",
      "630/630 [==============================] - 45s 72ms/step - loss: 0.3515 - accuracy: 0.8616 - val_loss: 0.4740 - val_accuracy: 0.8022\n",
      "Epoch 7/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.3286 - accuracy: 0.8701\n",
      "Epoch 7: val_accuracy did not improve from 0.82946\n",
      "630/630 [==============================] - 45s 72ms/step - loss: 0.3286 - accuracy: 0.8701 - val_loss: 1.0466 - val_accuracy: 0.6714\n",
      "Epoch 8/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.3430 - accuracy: 0.8636\n",
      "Epoch 8: val_accuracy did not improve from 0.82946\n",
      "630/630 [==============================] - 45s 71ms/step - loss: 0.3430 - accuracy: 0.8636 - val_loss: 0.5682 - val_accuracy: 0.7955\n",
      "Epoch 9/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.2943 - accuracy: 0.8850\n",
      "Epoch 9: val_accuracy improved from 0.82946 to 0.84330, saving model to D:/BMO/Main/savedModels\\0input_model_best.h5\n",
      "630/630 [==============================] - 45s 72ms/step - loss: 0.2943 - accuracy: 0.8850 - val_loss: 0.4174 - val_accuracy: 0.8433\n",
      "Epoch 10/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.2820 - accuracy: 0.8865\n",
      "Epoch 10: val_accuracy did not improve from 0.84330\n",
      "630/630 [==============================] - 45s 72ms/step - loss: 0.2820 - accuracy: 0.8865 - val_loss: 0.4778 - val_accuracy: 0.8094\n",
      "Epoch 11/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.2903 - accuracy: 0.8861\n",
      "Epoch 11: val_accuracy improved from 0.84330 to 0.84911, saving model to D:/BMO/Main/savedModels\\0input_model_best.h5\n",
      "630/630 [==============================] - 45s 71ms/step - loss: 0.2903 - accuracy: 0.8861 - val_loss: 0.3749 - val_accuracy: 0.8491\n",
      "Epoch 12/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.2855 - accuracy: 0.8887\n",
      "Epoch 12: val_accuracy did not improve from 0.84911\n",
      "630/630 [==============================] - 45s 71ms/step - loss: 0.2855 - accuracy: 0.8887 - val_loss: 0.5225 - val_accuracy: 0.8147\n",
      "Epoch 13/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.3153 - accuracy: 0.8781\n",
      "Epoch 13: val_accuracy did not improve from 0.84911\n",
      "630/630 [==============================] - 45s 71ms/step - loss: 0.3153 - accuracy: 0.8781 - val_loss: 0.4723 - val_accuracy: 0.8246\n",
      "Epoch 14/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.2476 - accuracy: 0.9037\n",
      "Epoch 14: val_accuracy improved from 0.84911 to 0.85402, saving model to D:/BMO/Main/savedModels\\0input_model_best.h5\n",
      "630/630 [==============================] - 45s 72ms/step - loss: 0.2476 - accuracy: 0.9037 - val_loss: 0.3885 - val_accuracy: 0.8540\n",
      "Epoch 15/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.2672 - accuracy: 0.8925\n",
      "Epoch 15: val_accuracy improved from 0.85402 to 0.85893, saving model to D:/BMO/Main/savedModels\\0input_model_best.h5\n",
      "630/630 [==============================] - 45s 72ms/step - loss: 0.2672 - accuracy: 0.8925 - val_loss: 0.3813 - val_accuracy: 0.8589\n",
      "Epoch 16/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.2603 - accuracy: 0.8999\n",
      "Epoch 16: val_accuracy did not improve from 0.85893\n",
      "630/630 [==============================] - 45s 72ms/step - loss: 0.2603 - accuracy: 0.8999 - val_loss: 0.4568 - val_accuracy: 0.8393\n",
      "Epoch 17/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.2640 - accuracy: 0.9003\n",
      "Epoch 17: val_accuracy did not improve from 0.85893\n",
      "630/630 [==============================] - 45s 72ms/step - loss: 0.2640 - accuracy: 0.9003 - val_loss: 0.4401 - val_accuracy: 0.8482\n",
      "Epoch 18/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.2726 - accuracy: 0.8959\n",
      "Epoch 18: val_accuracy did not improve from 0.85893\n",
      "630/630 [==============================] - 46s 74ms/step - loss: 0.2726 - accuracy: 0.8959 - val_loss: 0.4758 - val_accuracy: 0.8406\n",
      "Epoch 19/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.2461 - accuracy: 0.9051\n",
      "Epoch 19: val_accuracy did not improve from 0.85893\n",
      "630/630 [==============================] - 46s 73ms/step - loss: 0.2461 - accuracy: 0.9051 - val_loss: 0.4261 - val_accuracy: 0.8509\n",
      "Epoch 20/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.2588 - accuracy: 0.9014\n",
      "Epoch 20: val_accuracy did not improve from 0.85893\n",
      "630/630 [==============================] - 45s 72ms/step - loss: 0.2588 - accuracy: 0.9014 - val_loss: 0.4373 - val_accuracy: 0.8522\n",
      "Epoch 21/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.2413 - accuracy: 0.9049\n",
      "Epoch 21: val_accuracy did not improve from 0.85893\n",
      "630/630 [==============================] - 45s 72ms/step - loss: 0.2413 - accuracy: 0.9049 - val_loss: 0.4380 - val_accuracy: 0.8438\n",
      "Epoch 22/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.2421 - accuracy: 0.9057\n",
      "Epoch 22: val_accuracy did not improve from 0.85893\n",
      "630/630 [==============================] - 45s 72ms/step - loss: 0.2421 - accuracy: 0.9057 - val_loss: 0.5455 - val_accuracy: 0.8281\n",
      "Epoch 23/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.2325 - accuracy: 0.9111\n",
      "Epoch 23: val_accuracy did not improve from 0.85893\n",
      "630/630 [==============================] - 45s 71ms/step - loss: 0.2325 - accuracy: 0.9111 - val_loss: 0.5330 - val_accuracy: 0.8339\n",
      "Epoch 24/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.2217 - accuracy: 0.9132\n",
      "Epoch 24: val_accuracy did not improve from 0.85893\n",
      "630/630 [==============================] - 46s 73ms/step - loss: 0.2217 - accuracy: 0.9132 - val_loss: 0.4753 - val_accuracy: 0.8406\n",
      "Epoch 25/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.2315 - accuracy: 0.9101\n",
      "Epoch 25: val_accuracy did not improve from 0.85893\n",
      "630/630 [==============================] - 46s 73ms/step - loss: 0.2315 - accuracy: 0.9101 - val_loss: 0.8455 - val_accuracy: 0.7839\n",
      "Epoch 26/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.2514 - accuracy: 0.9064\n",
      "Epoch 26: val_accuracy did not improve from 0.85893\n",
      "630/630 [==============================] - 46s 73ms/step - loss: 0.2514 - accuracy: 0.9064 - val_loss: 0.6131 - val_accuracy: 0.8237\n",
      "Epoch 27/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.2240 - accuracy: 0.9151\n",
      "Epoch 27: val_accuracy did not improve from 0.85893\n",
      "630/630 [==============================] - 46s 73ms/step - loss: 0.2240 - accuracy: 0.9151 - val_loss: 0.5292 - val_accuracy: 0.8393\n",
      "Epoch 28/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.2346 - accuracy: 0.9107\n",
      "Epoch 28: val_accuracy did not improve from 0.85893\n",
      "630/630 [==============================] - 46s 74ms/step - loss: 0.2346 - accuracy: 0.9107 - val_loss: 0.6293 - val_accuracy: 0.8071\n",
      "Epoch 29/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.2240 - accuracy: 0.9163\n",
      "Epoch 29: val_accuracy did not improve from 0.85893\n",
      "630/630 [==============================] - 46s 73ms/step - loss: 0.2240 - accuracy: 0.9163 - val_loss: 1.5337 - val_accuracy: 0.7009\n",
      "Epoch 30/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.2369 - accuracy: 0.9107\n",
      "Epoch 30: val_accuracy did not improve from 0.85893\n",
      "630/630 [==============================] - 45s 72ms/step - loss: 0.2369 - accuracy: 0.9107 - val_loss: 0.5035 - val_accuracy: 0.8406\n",
      "Epoch 31/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.2429 - accuracy: 0.9099\n",
      "Epoch 31: val_accuracy did not improve from 0.85893\n",
      "630/630 [==============================] - 45s 72ms/step - loss: 0.2429 - accuracy: 0.9099 - val_loss: 0.5241 - val_accuracy: 0.8371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: early stopping\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.5184 - accuracy: 0.8357\n",
      "175/175 [==============================] - 3s 18ms/step\n",
      "[0.70935961 0.75489534 0.99263933 0.8950059 ]\n",
      "[0.73900293 0.76785714 0.99090273 0.84233901]\n",
      "..........Training set..........\n",
      "(20160, 2048, 1)\n",
      "(20160,)\n",
      "..........Validation set..........\n",
      "(2240, 2048, 1)\n",
      "(2240,)\n",
      "..........Testing set..........\n",
      "(5600, 2048, 1)\n",
      "(5600,)\n",
      "Epoch 1/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 1.2050 - accuracy: 0.6632\n",
      "Epoch 1: val_accuracy improved from -inf to 0.77857, saving model to D:/BMO/Main/savedModels\\0input_model_best.h5\n",
      "630/630 [==============================] - 52s 79ms/step - loss: 1.2050 - accuracy: 0.6632 - val_loss: 0.4997 - val_accuracy: 0.7786\n",
      "Epoch 2/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.4447 - accuracy: 0.8177\n",
      "Epoch 2: val_accuracy improved from 0.77857 to 0.85179, saving model to D:/BMO/Main/savedModels\\0input_model_best.h5\n",
      "630/630 [==============================] - 51s 81ms/step - loss: 0.4447 - accuracy: 0.8177 - val_loss: 0.3694 - val_accuracy: 0.8518\n",
      "Epoch 3/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.3890 - accuracy: 0.8429\n",
      "Epoch 3: val_accuracy did not improve from 0.85179\n",
      "630/630 [==============================] - 51s 81ms/step - loss: 0.3890 - accuracy: 0.8429 - val_loss: 0.7990 - val_accuracy: 0.6978\n",
      "Epoch 4/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.3467 - accuracy: 0.8654\n",
      "Epoch 4: val_accuracy did not improve from 0.85179\n",
      "630/630 [==============================] - 50s 80ms/step - loss: 0.3467 - accuracy: 0.8654 - val_loss: 0.3815 - val_accuracy: 0.8491\n",
      "Epoch 5/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.2925 - accuracy: 0.8850\n",
      "Epoch 5: val_accuracy did not improve from 0.85179\n",
      "630/630 [==============================] - 51s 80ms/step - loss: 0.2925 - accuracy: 0.8850 - val_loss: 0.9343 - val_accuracy: 0.6799\n",
      "Epoch 6/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.2785 - accuracy: 0.8894\n",
      "Epoch 6: val_accuracy improved from 0.85179 to 0.88437, saving model to D:/BMO/Main/savedModels\\0input_model_best.h5\n",
      "630/630 [==============================] - 50s 80ms/step - loss: 0.2785 - accuracy: 0.8894 - val_loss: 0.2862 - val_accuracy: 0.8844\n",
      "Epoch 7/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.2623 - accuracy: 0.8983\n",
      "Epoch 7: val_accuracy did not improve from 0.88437\n",
      "630/630 [==============================] - 50s 79ms/step - loss: 0.2623 - accuracy: 0.8983 - val_loss: 0.3863 - val_accuracy: 0.8607\n",
      "Epoch 8/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.2539 - accuracy: 0.9056\n",
      "Epoch 8: val_accuracy did not improve from 0.88437\n",
      "630/630 [==============================] - 50s 79ms/step - loss: 0.2539 - accuracy: 0.9056 - val_loss: 0.3164 - val_accuracy: 0.8804\n",
      "Epoch 9/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.2661 - accuracy: 0.9028\n",
      "Epoch 9: val_accuracy did not improve from 0.88437\n",
      "630/630 [==============================] - 38s 60ms/step - loss: 0.2661 - accuracy: 0.9028 - val_loss: 0.4891 - val_accuracy: 0.8321\n",
      "Epoch 10/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.2237 - accuracy: 0.9140\n",
      "Epoch 10: val_accuracy did not improve from 0.88437\n",
      "630/630 [==============================] - 29s 47ms/step - loss: 0.2237 - accuracy: 0.9140 - val_loss: 0.3864 - val_accuracy: 0.8674\n",
      "Epoch 11/100\n",
      "629/630 [============================>.] - ETA: 0s - loss: 0.2233 - accuracy: 0.9148\n",
      "Epoch 11: val_accuracy did not improve from 0.88437\n",
      "630/630 [==============================] - 29s 46ms/step - loss: 0.2232 - accuracy: 0.9149 - val_loss: 0.3689 - val_accuracy: 0.8737\n",
      "Epoch 12/100\n",
      "629/630 [============================>.] - ETA: 0s - loss: 0.1885 - accuracy: 0.9277\n",
      "Epoch 12: val_accuracy did not improve from 0.88437\n",
      "630/630 [==============================] - 29s 46ms/step - loss: 0.1883 - accuracy: 0.9277 - val_loss: 0.3050 - val_accuracy: 0.8835\n",
      "Epoch 13/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.2134 - accuracy: 0.9187\n",
      "Epoch 13: val_accuracy did not improve from 0.88437\n",
      "630/630 [==============================] - 30s 48ms/step - loss: 0.2134 - accuracy: 0.9187 - val_loss: 0.4824 - val_accuracy: 0.8420\n",
      "Epoch 14/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.1849 - accuracy: 0.9277\n",
      "Epoch 14: val_accuracy did not improve from 0.88437\n",
      "630/630 [==============================] - 30s 47ms/step - loss: 0.1849 - accuracy: 0.9277 - val_loss: 0.3487 - val_accuracy: 0.8839\n",
      "Epoch 15/100\n",
      "629/630 [============================>.] - ETA: 0s - loss: 0.2043 - accuracy: 0.9241\n",
      "Epoch 15: val_accuracy did not improve from 0.88437\n",
      "630/630 [==============================] - 29s 46ms/step - loss: 0.2043 - accuracy: 0.9241 - val_loss: 0.3935 - val_accuracy: 0.8665\n",
      "Epoch 16/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.1800 - accuracy: 0.9303\n",
      "Epoch 16: val_accuracy improved from 0.88437 to 0.89018, saving model to D:/BMO/Main/savedModels\\0input_model_best.h5\n",
      "630/630 [==============================] - 29s 46ms/step - loss: 0.1800 - accuracy: 0.9303 - val_loss: 0.3369 - val_accuracy: 0.8902\n",
      "Epoch 17/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.2224 - accuracy: 0.9159\n",
      "Epoch 17: val_accuracy improved from 0.89018 to 0.89420, saving model to D:/BMO/Main/savedModels\\0input_model_best.h5\n",
      "630/630 [==============================] - 29s 47ms/step - loss: 0.2224 - accuracy: 0.9159 - val_loss: 0.3264 - val_accuracy: 0.8942\n",
      "Epoch 18/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.1989 - accuracy: 0.9278\n",
      "Epoch 18: val_accuracy did not improve from 0.89420\n",
      "630/630 [==============================] - 29s 46ms/step - loss: 0.1989 - accuracy: 0.9278 - val_loss: 0.5368 - val_accuracy: 0.8402\n",
      "Epoch 19/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.1698 - accuracy: 0.9358\n",
      "Epoch 19: val_accuracy did not improve from 0.89420\n",
      "630/630 [==============================] - 29s 47ms/step - loss: 0.1698 - accuracy: 0.9358 - val_loss: 0.4776 - val_accuracy: 0.8652\n",
      "Epoch 20/100\n",
      "629/630 [============================>.] - ETA: 0s - loss: 0.1564 - accuracy: 0.9408\n",
      "Epoch 20: val_accuracy improved from 0.89420 to 0.90000, saving model to D:/BMO/Main/savedModels\\0input_model_best.h5\n",
      "630/630 [==============================] - 29s 46ms/step - loss: 0.1566 - accuracy: 0.9407 - val_loss: 0.3248 - val_accuracy: 0.9000\n",
      "Epoch 21/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.2175 - accuracy: 0.9290\n",
      "Epoch 21: val_accuracy did not improve from 0.90000\n",
      "630/630 [==============================] - 30s 47ms/step - loss: 0.2175 - accuracy: 0.9290 - val_loss: 0.3500 - val_accuracy: 0.8848\n",
      "Epoch 22/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.1435 - accuracy: 0.9447\n",
      "Epoch 22: val_accuracy did not improve from 0.90000\n",
      "630/630 [==============================] - 29s 46ms/step - loss: 0.1435 - accuracy: 0.9447 - val_loss: 0.3654 - val_accuracy: 0.8844\n",
      "Epoch 23/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.1843 - accuracy: 0.9340\n",
      "Epoch 23: val_accuracy did not improve from 0.90000\n",
      "630/630 [==============================] - 29s 47ms/step - loss: 0.1843 - accuracy: 0.9340 - val_loss: 0.7144 - val_accuracy: 0.8246\n",
      "Epoch 24/100\n",
      "629/630 [============================>.] - ETA: 0s - loss: 0.2791 - accuracy: 0.9201\n",
      "Epoch 24: val_accuracy did not improve from 0.90000\n",
      "630/630 [==============================] - 29s 46ms/step - loss: 0.2791 - accuracy: 0.9199 - val_loss: 0.4305 - val_accuracy: 0.8759\n",
      "Epoch 25/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.1513 - accuracy: 0.9425\n",
      "Epoch 25: val_accuracy did not improve from 0.90000\n",
      "630/630 [==============================] - 29s 46ms/step - loss: 0.1513 - accuracy: 0.9425 - val_loss: 0.4764 - val_accuracy: 0.8656\n",
      "Epoch 26/100\n",
      "630/630 [==============================] - ETA: 0s - loss: 0.1759 - accuracy: 0.9378\n",
      "Epoch 26: val_accuracy did not improve from 0.90000\n",
      "630/630 [==============================] - 30s 47ms/step - loss: 0.1759 - accuracy: 0.9378 - val_loss: 0.5949 - val_accuracy: 0.8433\n",
      "Epoch 26: early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n",
      "Confusion Matrix when Symbol Length  2048\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 0.5668 - accuracy: 0.8473\n",
      "175/175 [==============================] - 2s 12ms/step\n",
      "[0.74668528 0.74847126 0.99686083 0.88122097]\n",
      "[0.78445748 0.63049451 1.         0.98297557]\n",
      "CPU times: total: 3h 29min 44s\n",
      "Wall time: 1h 5min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "f1_bp = []\n",
    "f1_qp = []\n",
    "f1_16 = []\n",
    "f1_64 = []\n",
    "re_bp = []\n",
    "re_qp = []\n",
    "re_16 = []\n",
    "re_64 = []\n",
    "pr_bp = []\n",
    "pr_qp = []\n",
    "pr_16 = []\n",
    "pr_64 = []\n",
    "ac_bp = []\n",
    "ac_qp = []\n",
    "ac_16 = []\n",
    "ac_64 = []\n",
    "\n",
    "f1mc_bp = []\n",
    "f1mc_qp = []\n",
    "f1mc_16 = []\n",
    "f1mc_64 = []\n",
    "remc_bp = []\n",
    "remc_qp = []\n",
    "remc_16 = []\n",
    "remc_64 = []\n",
    "prmc_bp = []\n",
    "prmc_qp = []\n",
    "prmc_16 = []\n",
    "prmc_64 = []\n",
    "acmc_bp = []\n",
    "acmc_qp = []\n",
    "acmc_16 = []\n",
    "acmc_64 = []\n",
    "\n",
    "accuracy = []\n",
    "f1score = []\n",
    "loss = []\n",
    "precision = []\n",
    "false_pos = []\n",
    "true_pos = []\n",
    "recall = []\n",
    "\n",
    "for LENGTH in symbol_length:\n",
    "    \n",
    "    # Separating X and y\n",
    "    y = df_all['Mod'] # 1D targer vector\n",
    "    X = df_all.drop(columns='Mod')\n",
    "\n",
    "    INPUT_SHAPE = (LENGTH,1)\n",
    "\n",
    "    X.drop(X.iloc[:, LENGTH:2048], inplace = True, axis = 1)\n",
    "\n",
    "    X = np.expand_dims(X, -1)\n",
    "\n",
    "    # Split into training/testing sets with 20% split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=1)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=1) \n",
    "\n",
    "    print(\"..........Training set..........\")\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(\"..........Validation set..........\")\n",
    "    print(X_val.shape)\n",
    "    print(y_val.shape)\n",
    "    print(\"..........Testing set..........\")\n",
    "    print(X_test.shape)\n",
    "    print(y_test.shape)\n",
    "\n",
    "    # Convert class vectors to categorical classes matrices\n",
    "    y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "    y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
    "    y_val = np_utils.to_categorical(y_val, NB_CLASSES)\n",
    "\n",
    "    from keras.constraints import maxnorm\n",
    "\n",
    "    # Function to create model, required for KerasClassifier\n",
    "    def create_model():\n",
    "        # create model\n",
    "        model = Sequential()\n",
    "        filter_num = ['None',32,64,128,256]\n",
    "        kernel_size = ['None',8,8,8,8]\n",
    "        conv_stride_size = ['None',1,1,1,1]\n",
    "        pool_stride_size = ['None',4,4,4,4]\n",
    "        pool_size = ['None',8,8,8,8]\n",
    "        batch_size = 10\n",
    "        dropout_rate =0.0\n",
    "        # Feature extraction\n",
    "        model.add(Conv1D(filters=filter_num[1], kernel_size=kernel_size[1], input_shape=INPUT_SHAPE,\n",
    "                             strides=conv_stride_size[1], padding='same',\n",
    "                             name='convolution1'))\n",
    "        model.add(BatchNormalization(axis=-1))\n",
    "        model.add(ELU(alpha=1.0, name='activation1'))\n",
    "        model.add(MaxPooling1D(pool_size=pool_size[1], strides=pool_stride_size[1],\n",
    "                                   padding='same', name='pool1'))\n",
    "        model.add(Dropout(dropout_rate, name='dropout1'))\n",
    "        \n",
    "        model.add(BatchNormalization(axis=-1))\n",
    "        model.add(ELU(alpha=1.0, name='activation2'))\n",
    "        model.add(MaxPooling1D(pool_size=pool_size[2], strides=pool_stride_size[2],\n",
    "                                   padding='same', name='pool2'))\n",
    "        model.add(Dropout(dropout_rate, name='dropout2'))\n",
    "\n",
    "        # Output layer\n",
    "        model.add(Flatten(name='flatten1'))\n",
    "        model.add(Dense(NB_CLASSES, kernel_initializer=glorot_uniform(seed=0), name='dense1'))\n",
    "        model.add(Activation('softmax', name=\"softmax\"))\n",
    "\n",
    "        # Compile model\n",
    "        model.compile(loss=\"categorical_crossentropy\", optimizer=SGD(lr=0.01, momentum=0.6), metrics=[\"accuracy\"])\n",
    "\n",
    "        return model\n",
    "\n",
    "    model = create_model()\n",
    "    # simple early stopping\n",
    "    es_lr = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
    "    mc_lr = ModelCheckpoint(file_best, monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "    # fit model\n",
    "    model_history = model.fit(X_train, y_train, epochs=NB_EPOCH, verbose=VERBOSE, \n",
    "                                validation_data=(X_val, y_val), callbacks=[es_lr, mc_lr])\n",
    "  #  model_history = model.fit(X_train, y_train, epochs=NB_EPOCH, verbose=VERBOSE, \n",
    "   #                             validation_data=(X_val, y_val))\n",
    "    \n",
    "    \n",
    "    if(LENGTH==128):\n",
    "        save_model(model, file_short)\n",
    "        print(\"Saved model to disk\")\n",
    "        print('Confusion Matrix when Symbol Length ', LENGTH)\n",
    "        cm_short = confusion_matrix(y_test1, y_pred1)\n",
    "        cmratio_short = cm_short.astype('float') / cm_short.sum(axis=1)[:, np.newaxis]\n",
    "        cmratio_short= np.around(cmratio_short.astype('float') / cmratio_short.sum(axis=1)[:, np.newaxis], decimals=1)\n",
    "        \n",
    "    if(LENGTH==512):\n",
    "        save_model(model, file_mid1)\n",
    "        print(\"Saved model to disk\")\n",
    "        print('Confusion Matrix when Symbol Length ', LENGTH)\n",
    "        cm_mid1 = confusion_matrix(y_test1, y_pred1)\n",
    "        cmratio_mid1 = cm_mid1.astype('float') / cm_mid1.sum(axis=1)[:, np.newaxis]\n",
    "        cmratio_mid1= np.around(cmratio_mid1.astype('float') / cmratio_mid1.sum(axis=1)[:, np.newaxis], decimals=1)\n",
    "        \n",
    "    if(LENGTH==1536):\n",
    "        save_model(model, file_mid2)\n",
    "        print(\"Saved model to disk\")\n",
    "        print('Confusion Matrix when Symbol Length ', LENGTH)\n",
    "        cm_mid2 = confusion_matrix(y_test1, y_pred1)\n",
    "        cmratio_mid2 = cm_mid2.astype('float') / cm_mid2.sum(axis=1)[:, np.newaxis]\n",
    "        cmratio_mid2= np.around(cmratio_mid2.astype('float') / cmratio_mid2.sum(axis=1)[:, np.newaxis], decimals=1)\n",
    "        \n",
    "    if(LENGTH==2048):\n",
    "        save_model(model, file_long)\n",
    "        print(\"Saved model to disk\")\n",
    "        print('Confusion Matrix when Symbol Length ', LENGTH)\n",
    "        cm_long = confusion_matrix(y_test1, y_pred1)\n",
    "        cmratio_long = cm_long.astype('float') / cm_long.sum(axis=1)[:, np.newaxis]\n",
    "        cmratio_long= np.around(cmratio_long.astype('float') / cmratio_long.sum(axis=1)[:, np.newaxis], decimals=1)\n",
    "        \n",
    "    # Start evaluating model with testing data\n",
    "    score_test = model.evaluate(X_test, y_test, verbose=VERBOSE)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    y_pred1=np.argmax(y_pred, axis=1)\n",
    "    y_test1=np.argmax(y_test, axis=1)\n",
    "    #cm = confusion_matrix(y_test1, y_pred1\n",
    "    \n",
    "    acc = score_test[1]\n",
    "    accuracy.append(acc)\n",
    "    \n",
    "    ls = score_test[0]\n",
    "    loss.append(ls)\n",
    "    \n",
    "    f1s = f1_score(y_test1, y_pred1, average=None)\n",
    "    f1score.append((f1s[0]+f1s[1])/2)\n",
    "    print(f1s)\n",
    "    for index, val in np.ndenumerate(f1s):\n",
    "            if (index[0]==0): \n",
    "                f1bp = val\n",
    "            if (index[0]==1): \n",
    "                f1qp = val\n",
    "            if (index[0]==2):\n",
    "                f116 = val\n",
    "            if (index[0]==3): \n",
    "                f164 = val\n",
    "           \n",
    "    f1_bp.append(f1bp)\n",
    "    f1_qp.append(f1qp)\n",
    "    f1_16.append(f116)\n",
    "    f1_64.append(f164)\n",
    "    \n",
    "    \n",
    "    cm = confusion_matrix(y_test1, y_pred1)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    #print('Confusion Matrix when Symbol Length ', LENGTH)\n",
    "    #f = sns.heatmap(cm, cmap='Greens', annot=True, square=True, yticklabels = True)\n",
    "    #cmratio = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    #plt.rcParams[\"figure.figsize\"] = (7.5,7.5)\n",
    "    #plt.rcParams.update({'font.size': 14})\n",
    "    #f = sns.heatmap(cm, cmap='Purples', annot=True, square=True, yticklabels = True)\n",
    "    \n",
    "    accuracys = cm.diagonal()\n",
    "    #acc = accuracy.reshape(-1,1)\n",
    "    print(accuracys)\n",
    "    for index, val in np.ndenumerate(accuracys):\n",
    "            if (index[0]==0): \n",
    "                abp = val\n",
    "            if (index[0]==1): \n",
    "                aqp = val\n",
    "            if (index[0]==2):\n",
    "                a16 = val\n",
    "            if (index[0]==3): \n",
    "                a64 = val\n",
    "           \n",
    "    ac_bp.append(abp)\n",
    "    ac_qp.append(aqp)\n",
    "    ac_16.append(a16)\n",
    "    ac_64.append(a64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75337dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbol series length =  2048\n",
      "[[1070   78    3  213]\n",
      " [ 410  918    6  122]\n",
      " [   0    0 1429    0]\n",
      " [  22    1    0 1328]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Symbol series length = \", LENGTH)\n",
    "\n",
    "y_pred1=np.argmax(y_pred, axis=1)\n",
    "y_test1=np.argmax(y_test, axis=1)\n",
    "cm = confusion_matrix(y_test1, y_pred1)\n",
    "print(cm)\n",
    "#f = sns.heatmap(cm, cmap='Purples', annot=True, square=True, yticklabels = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c722b45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24017857015132904, 0.5483928322792053, 0.7162500023841858, 0.8357142806053162, 0.8473214507102966]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf399dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24017857015132904, 0.5483928322792053, 0.7162500023841858, 0.8357142806053162, 0.8473214507102966]\n",
      "[1.3931570053100586, 0.9872667789459229, 1.0511842966079712, 0.5184050798416138, 0.5668250322341919]\n",
      "[0.16810530858869227, 0.43470774142869434, 0.5564906500850606, 0.7321274734485752, 0.7475782676637605]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(accuracy)\n",
    "print(loss)\n",
    "print(f1score)\n",
    "# Plot Graph\n",
    "plt.rcParams[\"figure.figsize\"] = (8,6)\n",
    "plt.rcParams.update({'font.size': 30})\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.plot(symbol_length, accuracy, color='b', linestyle='dashed', linewidth =4,\n",
    "         marker='x', markerfacecolor='white', markersize=22, label='Accuracy')\n",
    "ax1.plot(symbol_length, f1score, color='k', linestyle=':', linewidth =4,\n",
    "         marker='o', markerfacecolor='k', markersize=14, label='F1-score')\n",
    "ax1.plot(symbol_length, loss, color='r', linestyle='-', linewidth = 2,\n",
    "         marker='s', markerfacecolor='r', markersize=12, label='Loss')\n",
    "\n",
    "ax1.set_xlabel('Number of symbols per data sample')\n",
    "#ax1.set_ylabel('Score')\n",
    "plt.grid()\n",
    "#plt.ylim(0.14, 1.0)\n",
    "# ask matplotlib for the plotted objects and their labels\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "#lines2, labels2 = ax1.get_legend_handles_labels()\n",
    "ax1.legend(lines, labels, loc='center right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cdfcf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "test_hypertune-fixedEncrypt.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
