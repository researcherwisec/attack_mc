{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a378348",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3a378348",
    "outputId": "e3cd11aa-24d3-4dbe-826f-0a8c8f106417",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.1\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_curve\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "UfbIBKcs28fu",
   "metadata": {
    "id": "UfbIBKcs28fu"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, BatchNormalization\n",
    "from keras.layers.core import Activation, Flatten, Dense, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import ELU, PReLU, LeakyReLU\n",
    "#from keras.layers.advanced_activations import ELU\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "#from keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from math import floor\n",
    "from sklearn.metrics import make_scorer, accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "#from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.layers import LeakyReLU\n",
    "#LeakyReLU = LeakyReLU(alpha=0.1)\n",
    "from tensorflow.keras.models import save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "zXsyD8Tep5pL",
   "metadata": {
    "id": "zXsyD8Tep5pL"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount(\"/content/gdrive\")\n",
    "#!pip3 install graphviz\n",
    "#!pip3 install bayesian-optimization\n",
    "#!pip3 install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "Rn_T2kF828fy",
   "metadata": {
    "id": "Rn_T2kF828fy"
   },
   "outputs": [],
   "source": [
    "#print(bits_64qam)\n",
    "#symbol_length = [500] # Packet sequence length\n",
    "NB_CLASSES = 7 # number of outputs = number of classes\n",
    "VERBOSE = 1\n",
    "BATCH_SIZE = 10\n",
    "NB_EPOCH = 100\n",
    "target_names =  ['Ob(BPSK)', 'Ob2(QPSK)', 'Ob2(16-QAM)', 'Ob2(64-QAM)', 'Ob4(QPSK)', 'Ob4(16-QAM)', 'Ob4(64-QAM)']\n",
    "file_short = \"D:/BMO/Main/savedModels/7input_model_short.h5\"\n",
    "file_mid1 = \"D:/BMO/Main/savedModels/7input_model_mid1.h5\"\n",
    "file_mid2 = \"D:/BMO/Main/savedModels/7input_model_mid2.h5\"\n",
    "file_long = \"D:/BMO/Main/savedModels/7input_model_long.h5\"\n",
    "file_best = \"D:/BMO/Main/savedModels/7input_model_best.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "D13rz3nI0Hfc",
   "metadata": {
    "id": "D13rz3nI0Hfc"
   },
   "outputs": [],
   "source": [
    "#symbol_length =   [36, 100, 200, 250, 300, 350, 400, 450, 500]\n",
    "symbol_length =   [500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "N4PfpMME28f2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N4PfpMME28f2",
    "outputId": "a6153461-a119-4f2c-8fa8-db84616dad54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........Loading MO (2-state) dataset..........\n",
      "df_2st Shape =  (28000, 501)\n",
      "CPU times: total: 46.8 s\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\".........Loading MO (2-state) dataset..........\")\n",
    "\n",
    "# sep separates each column and header = none means it is going to read from row 1\n",
    "re2psk_2st = pd.read_csv('D:/BMO/Main/bigDataset/BPSK-2/real.xls',sep='\\t', header=None) \n",
    "im2psk_2st = pd.read_csv('D:/BMO/Main/bigDataset/BPSK-2/im.xls',sep='\\t', header=None)\n",
    "\n",
    "# sep separates each column and header = none means it is going to read from row 1\n",
    "re4psk_2st = pd.read_csv('D:/BMO/Main/bigDataset/QPSK-2/real.xls',sep='\\t', header=None) \n",
    "im4psk_2st = pd.read_csv('D:/BMO/Main/bigDataset/QPSK-2/im.xls',sep='\\t', header=None)\n",
    "\n",
    "# sep separates each column and header = none means it is going to read from row 1\n",
    "re16qam_2st = pd.read_csv('D:/BMO/Main/bigDataset/16-QAM-2/real.xls',sep='\\t', header=None) \n",
    "im16qam_2st = pd.read_csv('D:/BMO/Main/bigDataset/16-QAM-2/im.xls',sep='\\t', header=None)\n",
    "\n",
    "# sep separates each column and header = none means it is going to read from row 1\n",
    "re64qam_2st = pd.read_csv('D:/BMO/Main/bigDataset/64-QAM-2/real.xls',sep='\\t', header=None) \n",
    "im64qam_2st = pd.read_csv('D:/BMO/Main/bigDataset/64-QAM-2/im.xls',sep='\\t', header=None)\n",
    "\n",
    "#merge two dataframes into one\n",
    "df2psk_2st = re2psk_2st + im2psk_2st * 1j\n",
    "df2psk_2st.drop(df2psk_2st.iloc[:, 500:], inplace = True, axis = 1)\n",
    "df2psk_2st['Mod'] = 0 # 0 = BPSK 2-state\n",
    "#merge two dataframes into one\n",
    "df4psk_2st = re4psk_2st + im4psk_2st * 1j\n",
    "df4psk_2st.drop(df4psk_2st.iloc[:, 500:], inplace = True, axis = 1)\n",
    "df4psk_2st['Mod'] = 1 # 1 = QPSK 2-state\n",
    "#merge two dataframes into one\n",
    "df16qam_2st = re16qam_2st + im16qam_2st * 1j\n",
    "df16qam_2st.drop(df16qam_2st.iloc[:, 500:], inplace = True, axis = 1)\n",
    "df16qam_2st['Mod'] = 2 # 2 = 16-QAM 2-state\n",
    "#merge two dataframes into one\n",
    "df64qam_2st = re64qam_2st + im64qam_2st * 1j\n",
    "df64qam_2st.drop(df64qam_2st.iloc[:, 500:], inplace = True, axis = 1)\n",
    "df64qam_2st['Mod'] = 3 # 3 = 64-QAM 2-state\n",
    "\n",
    "\n",
    "# combine all\n",
    "df_2st = df2psk_2st.append(df4psk_2st)\n",
    "df_2st = df_2st.append(df16qam_2st)\n",
    "df_2st = df_2st.append(df64qam_2st)\n",
    "\n",
    "df_2st = df_2st.sample(frac = 1)\n",
    "print('df_2st Shape = ', df_2st.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "UyKInUwG28f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UyKInUwG28f6",
    "outputId": "9647a677-99f8-4554-ccd0-74ebffceed6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........Loading MO (4-state) dataset..........\n",
      "df_4st Shape =  (28000, 501)\n",
      "CPU times: total: 23.2 s\n",
      "Wall time: 34.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\".........Loading MO (4-state) dataset..........\")\n",
    "\n",
    "# sep separates each column and header = none means it is going to read from row 1\n",
    "re2psk_4st = pd.read_csv('D:/BMO/Main/bigDataset/BPSK-4/real.xls',sep='\\t', header=None) \n",
    "im2psk_4st = pd.read_csv('D:/BMO/Main/bigDataset/BPSK-4/im.xls',sep='\\t', header=None)\n",
    "\n",
    "# sep separates each column and header = none means it is going to read from row 1\n",
    "re4psk_4st = pd.read_csv('D:/BMO/Main/bigDataset/QPSK-4/real.xls',sep='\\t', header=None) \n",
    "im4psk_4st = pd.read_csv('D:/BMO/Main/bigDataset/QPSK-4/im.xls',sep='\\t', header=None)\n",
    "\n",
    "# sep separates each column and header = none means it is going to read from row 1\n",
    "re16qam_4st = pd.read_csv('D:/BMO/Main/bigDataset/16-QAM-4/real.xls',sep='\\t', header=None) \n",
    "im16qam_4st = pd.read_csv('D:/BMO/Main/bigDataset/16-QAM-4/im.xls',sep='\\t', header=None)\n",
    "\n",
    "# sep separates each column and header = none means it is going to read from row 1\n",
    "re64qam_4st = pd.read_csv('D:/BMO/Main/bigDataset/64-QAM-4/real.xls',sep='\\t', header=None) \n",
    "im64qam_4st = pd.read_csv('D:/BMO/Main/bigDataset/64-QAM-4/im.xls',sep='\\t', header=None)\n",
    "\n",
    "#merge two dataframes into one\n",
    "df2psk_4st = re2psk_4st + im2psk_4st * 1j\n",
    "df2psk_4st.drop(df2psk_4st.iloc[:, 500:], inplace = True, axis = 1)\n",
    "df2psk_4st['Mod'] = 0 # 0 = BPSK 2-state\n",
    "#merge two dataframes into one\n",
    "df4psk_4st = re4psk_4st + im4psk_4st * 1j\n",
    "df4psk_4st.drop(df4psk_4st.iloc[:, 500:], inplace = True, axis = 1)\n",
    "df4psk_4st['Mod'] = 4 # 1 = QPSK 2-state\n",
    "#merge two dataframes into one\n",
    "df16qam_4st = re16qam_4st + im16qam_4st * 1j\n",
    "df16qam_4st.drop(df16qam_4st.iloc[:, 500:], inplace = True, axis = 1)\n",
    "df16qam_4st['Mod'] = 5 # 2 = 16-QAM 2-state\n",
    "#merge two dataframes into one\n",
    "df64qam_4st = re64qam_4st + im64qam_4st * 1j\n",
    "df64qam_4st.drop(df64qam_4st.iloc[:, 500:], inplace = True, axis = 1)\n",
    "df64qam_4st['Mod'] = 6 # 3 = 64-QAM 2-state\n",
    "\n",
    "# combine all\n",
    "df_4st = df2psk_4st.append(df4psk_4st)\n",
    "df_4st = df_4st.append(df16qam_4st)\n",
    "df_4st = df_4st.append(df64qam_4st)\n",
    "\n",
    "df_4st = df_4st.sample(frac = 1)\n",
    "print('df_4st Shape = ', df_4st.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a63faf3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........Combining all data..........\n",
      "df_all Shape =  (56000, 501)\n",
      "..........Shuffling done..........\n",
      "df_all Size =  28056000\n",
      "Dimension =  2\n",
      "Combined Shape =  (56000, 501)\n"
     ]
    }
   ],
   "source": [
    "print(\"..........Combining all data..........\")\n",
    "\n",
    "# combine all\n",
    "df = df_2st.append(df_4st)\n",
    "df_all = df.sample(frac = 1)\n",
    "print('df_all Shape = ', df_all.shape)\n",
    "print(\"..........Shuffling done..........\")\n",
    "\n",
    "# reducing samples to tune only\n",
    "#df_all = df_all.iloc[:16384]\n",
    "print('df_all Size = ', df_all.size)\n",
    "print('Dimension = ', df_all.ndim)\n",
    "print('Combined Shape = ', df_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ftPgr69w28f7",
   "metadata": {
    "id": "ftPgr69w28f7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........Training set..........\n",
      "(40320, 500, 1)\n",
      "(40320,)\n",
      "..........Validation set..........\n",
      "(4480, 500, 1)\n",
      "(4480,)\n",
      "..........Testing set..........\n",
      "(11200, 500, 1)\n",
      "(11200,)\n",
      "Epoch 1/100\n",
      "1258/1260 [============================>.] - ETA: 0s - loss: 1.4926 - accuracy: 0.5260\n",
      "Epoch 1: val_accuracy improved from -inf to 0.73973, saving model to D:/BMO/Main/savedModels\\7input_model_best.h5\n",
      "1260/1260 [==============================] - 26s 20ms/step - loss: 1.4920 - accuracy: 0.5261 - val_loss: 0.7250 - val_accuracy: 0.7397\n",
      "Epoch 2/100\n",
      "1258/1260 [============================>.] - ETA: 0s - loss: 0.5216 - accuracy: 0.8198\n",
      "Epoch 2: val_accuracy improved from 0.73973 to 0.86004, saving model to D:/BMO/Main/savedModels\\7input_model_best.h5\n",
      "1260/1260 [==============================] - 23s 18ms/step - loss: 0.5215 - accuracy: 0.8198 - val_loss: 0.4099 - val_accuracy: 0.8600\n",
      "Epoch 3/100\n",
      "1260/1260 [==============================] - ETA: 0s - loss: 0.2991 - accuracy: 0.8991\n",
      "Epoch 3: val_accuracy improved from 0.86004 to 0.90357, saving model to D:/BMO/Main/savedModels\\7input_model_best.h5\n",
      "1260/1260 [==============================] - 16s 12ms/step - loss: 0.2991 - accuracy: 0.8991 - val_loss: 0.2831 - val_accuracy: 0.9036\n",
      "Epoch 4/100\n",
      "1257/1260 [============================>.] - ETA: 0s - loss: 0.1958 - accuracy: 0.9389\n",
      "Epoch 4: val_accuracy improved from 0.90357 to 0.94330, saving model to D:/BMO/Main/savedModels\\7input_model_best.h5\n",
      "1260/1260 [==============================] - 18s 14ms/step - loss: 0.1957 - accuracy: 0.9390 - val_loss: 0.1842 - val_accuracy: 0.9433\n",
      "Epoch 5/100\n",
      "1256/1260 [============================>.] - ETA: 0s - loss: 0.1602 - accuracy: 0.9494\n",
      "Epoch 5: val_accuracy did not improve from 0.94330\n",
      "1260/1260 [==============================] - 16s 12ms/step - loss: 0.1603 - accuracy: 0.9493 - val_loss: 0.3261 - val_accuracy: 0.8449\n",
      "Epoch 6/100\n",
      "1259/1260 [============================>.] - ETA: 0s - loss: 0.1256 - accuracy: 0.9612\n",
      "Epoch 6: val_accuracy did not improve from 0.94330\n",
      "1260/1260 [==============================] - 16s 12ms/step - loss: 0.1256 - accuracy: 0.9612 - val_loss: 0.2487 - val_accuracy: 0.9123\n",
      "Epoch 7/100\n",
      "1259/1260 [============================>.] - ETA: 0s - loss: 0.1080 - accuracy: 0.9678\n",
      "Epoch 7: val_accuracy improved from 0.94330 to 0.94464, saving model to D:/BMO/Main/savedModels\\7input_model_best.h5\n",
      "1260/1260 [==============================] - 16s 12ms/step - loss: 0.1080 - accuracy: 0.9678 - val_loss: 0.1496 - val_accuracy: 0.9446\n",
      "Epoch 8/100\n",
      "1259/1260 [============================>.] - ETA: 0s - loss: 0.0914 - accuracy: 0.9753\n",
      "Epoch 8: val_accuracy improved from 0.94464 to 0.95223, saving model to D:/BMO/Main/savedModels\\7input_model_best.h5\n",
      "1260/1260 [==============================] - 16s 12ms/step - loss: 0.0914 - accuracy: 0.9753 - val_loss: 0.1381 - val_accuracy: 0.9522\n",
      "Epoch 9/100\n",
      "1260/1260 [==============================] - ETA: 0s - loss: 0.0730 - accuracy: 0.9803\n",
      "Epoch 9: val_accuracy did not improve from 0.95223\n",
      "1260/1260 [==============================] - 16s 12ms/step - loss: 0.0730 - accuracy: 0.9803 - val_loss: 0.1389 - val_accuracy: 0.9518\n",
      "Epoch 10/100\n",
      "1259/1260 [============================>.] - ETA: 0s - loss: 0.0670 - accuracy: 0.9810\n",
      "Epoch 10: val_accuracy did not improve from 0.95223\n",
      "1260/1260 [==============================] - 16s 12ms/step - loss: 0.0670 - accuracy: 0.9810 - val_loss: 0.3083 - val_accuracy: 0.8924\n",
      "Epoch 11/100\n",
      "1256/1260 [============================>.] - ETA: 0s - loss: 0.0597 - accuracy: 0.9828\n",
      "Epoch 11: val_accuracy improved from 0.95223 to 0.96295, saving model to D:/BMO/Main/savedModels\\7input_model_best.h5\n",
      "1260/1260 [==============================] - 16s 12ms/step - loss: 0.0596 - accuracy: 0.9828 - val_loss: 0.1095 - val_accuracy: 0.9629\n",
      "Epoch 12/100\n",
      "1257/1260 [============================>.] - ETA: 0s - loss: 0.0521 - accuracy: 0.9860\n",
      "Epoch 12: val_accuracy did not improve from 0.96295\n",
      "1260/1260 [==============================] - 16s 12ms/step - loss: 0.0522 - accuracy: 0.9860 - val_loss: 0.2096 - val_accuracy: 0.9348\n",
      "Epoch 13/100\n",
      "1256/1260 [============================>.] - ETA: 0s - loss: 0.0446 - accuracy: 0.9888\n",
      "Epoch 13: val_accuracy improved from 0.96295 to 0.96317, saving model to D:/BMO/Main/savedModels\\7input_model_best.h5\n",
      "1260/1260 [==============================] - 16s 12ms/step - loss: 0.0446 - accuracy: 0.9888 - val_loss: 0.1064 - val_accuracy: 0.9632\n",
      "Epoch 14/100\n",
      "1260/1260 [==============================] - ETA: 0s - loss: 0.0459 - accuracy: 0.9884\n",
      "Epoch 14: val_accuracy did not improve from 0.96317\n",
      "1260/1260 [==============================] - 16s 12ms/step - loss: 0.0459 - accuracy: 0.9884 - val_loss: 0.1709 - val_accuracy: 0.9237\n",
      "Epoch 15/100\n",
      "1259/1260 [============================>.] - ETA: 0s - loss: 0.0388 - accuracy: 0.9897\n",
      "Epoch 15: val_accuracy did not improve from 0.96317\n",
      "1260/1260 [==============================] - 16s 12ms/step - loss: 0.0388 - accuracy: 0.9897 - val_loss: 0.1234 - val_accuracy: 0.9567\n",
      "Epoch 16/100\n",
      "1260/1260 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 0.9925\n",
      "Epoch 16: val_accuracy improved from 0.96317 to 0.96696, saving model to D:/BMO/Main/savedModels\\7input_model_best.h5\n",
      "1260/1260 [==============================] - 16s 12ms/step - loss: 0.0320 - accuracy: 0.9925 - val_loss: 0.1069 - val_accuracy: 0.9670\n",
      "Epoch 17/100\n",
      "1257/1260 [============================>.] - ETA: 0s - loss: 0.0306 - accuracy: 0.9928\n",
      "Epoch 17: val_accuracy did not improve from 0.96696\n",
      "1260/1260 [==============================] - 16s 13ms/step - loss: 0.0306 - accuracy: 0.9928 - val_loss: 0.1446 - val_accuracy: 0.9493\n",
      "Epoch 18/100\n",
      "1259/1260 [============================>.] - ETA: 0s - loss: 0.0274 - accuracy: 0.9941\n",
      "Epoch 18: val_accuracy improved from 0.96696 to 0.96942, saving model to D:/BMO/Main/savedModels\\7input_model_best.h5\n",
      "1260/1260 [==============================] - 16s 13ms/step - loss: 0.0274 - accuracy: 0.9940 - val_loss: 0.1002 - val_accuracy: 0.9694\n",
      "Epoch 19/100\n",
      "1259/1260 [============================>.] - ETA: 0s - loss: 0.0239 - accuracy: 0.9950\n",
      "Epoch 19: val_accuracy did not improve from 0.96942\n",
      "1260/1260 [==============================] - 16s 13ms/step - loss: 0.0239 - accuracy: 0.9950 - val_loss: 0.0939 - val_accuracy: 0.9685\n",
      "Epoch 20/100\n",
      "1260/1260 [==============================] - ETA: 0s - loss: 0.0427 - accuracy: 0.9915\n",
      "Epoch 20: val_accuracy did not improve from 0.96942\n",
      "1260/1260 [==============================] - 16s 13ms/step - loss: 0.0427 - accuracy: 0.9915 - val_loss: 0.1061 - val_accuracy: 0.9661\n",
      "Epoch 21/100\n",
      "1258/1260 [============================>.] - ETA: 0s - loss: 0.0243 - accuracy: 0.9943\n",
      "Epoch 21: val_accuracy did not improve from 0.96942\n",
      "1260/1260 [==============================] - 16s 12ms/step - loss: 0.0243 - accuracy: 0.9943 - val_loss: 0.1249 - val_accuracy: 0.9607\n",
      "Epoch 22/100\n",
      "1259/1260 [============================>.] - ETA: 0s - loss: 0.0171 - accuracy: 0.9971\n",
      "Epoch 22: val_accuracy did not improve from 0.96942\n",
      "1260/1260 [==============================] - 15s 12ms/step - loss: 0.0171 - accuracy: 0.9971 - val_loss: 0.1015 - val_accuracy: 0.9683\n",
      "Epoch 23/100\n",
      "1258/1260 [============================>.] - ETA: 0s - loss: 0.0148 - accuracy: 0.9979\n",
      "Epoch 23: val_accuracy did not improve from 0.96942\n",
      "1260/1260 [==============================] - 15s 12ms/step - loss: 0.0149 - accuracy: 0.9978 - val_loss: 0.1025 - val_accuracy: 0.9663\n",
      "Epoch 24/100\n",
      "1258/1260 [============================>.] - ETA: 0s - loss: 0.0133 - accuracy: 0.9981\n",
      "Epoch 24: val_accuracy did not improve from 0.96942\n",
      "1260/1260 [==============================] - 15s 12ms/step - loss: 0.0133 - accuracy: 0.9981 - val_loss: 0.1057 - val_accuracy: 0.9676\n",
      "Epoch 25/100\n",
      "1256/1260 [============================>.] - ETA: 0s - loss: 0.0126 - accuracy: 0.9982\n",
      "Epoch 25: val_accuracy improved from 0.96942 to 0.97188, saving model to D:/BMO/Main/savedModels\\7input_model_best.h5\n",
      "1260/1260 [==============================] - 15s 12ms/step - loss: 0.0126 - accuracy: 0.9982 - val_loss: 0.0940 - val_accuracy: 0.9719\n",
      "Epoch 26/100\n",
      "1259/1260 [============================>.] - ETA: 0s - loss: 0.0108 - accuracy: 0.9990\n",
      "Epoch 26: val_accuracy did not improve from 0.97188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1260/1260 [==============================] - 15s 12ms/step - loss: 0.0108 - accuracy: 0.9989 - val_loss: 0.0983 - val_accuracy: 0.9696\n",
      "Epoch 27/100\n",
      "1257/1260 [============================>.] - ETA: 0s - loss: 0.0100 - accuracy: 0.9991\n",
      "Epoch 27: val_accuracy improved from 0.97188 to 0.97232, saving model to D:/BMO/Main/savedModels\\7input_model_best.h5\n",
      "1260/1260 [==============================] - 15s 12ms/step - loss: 0.0100 - accuracy: 0.9991 - val_loss: 0.0957 - val_accuracy: 0.9723\n",
      "Epoch 28/100\n",
      "1257/1260 [============================>.] - ETA: 0s - loss: 0.0096 - accuracy: 0.9989\n",
      "Epoch 28: val_accuracy improved from 0.97232 to 0.97254, saving model to D:/BMO/Main/savedModels\\7input_model_best.h5\n",
      "1260/1260 [==============================] - 15s 12ms/step - loss: 0.0096 - accuracy: 0.9989 - val_loss: 0.0928 - val_accuracy: 0.9725\n",
      "Epoch 29/100\n",
      "1260/1260 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.9996\n",
      "Epoch 29: val_accuracy improved from 0.97254 to 0.97522, saving model to D:/BMO/Main/savedModels\\7input_model_best.h5\n",
      "1260/1260 [==============================] - 15s 12ms/step - loss: 0.0079 - accuracy: 0.9996 - val_loss: 0.0917 - val_accuracy: 0.9752\n",
      "Epoch 30/100\n",
      "1257/1260 [============================>.] - ETA: 0s - loss: 0.0132 - accuracy: 0.9975\n",
      "Epoch 30: val_accuracy did not improve from 0.97522\n",
      "1260/1260 [==============================] - 16s 12ms/step - loss: 0.0132 - accuracy: 0.9975 - val_loss: 0.1083 - val_accuracy: 0.9665\n",
      "Epoch 31/100\n",
      "1257/1260 [============================>.] - ETA: 0s - loss: 0.0083 - accuracy: 0.9995\n",
      "Epoch 31: val_accuracy did not improve from 0.97522\n",
      "1260/1260 [==============================] - 16s 12ms/step - loss: 0.0083 - accuracy: 0.9995 - val_loss: 0.1078 - val_accuracy: 0.9690\n",
      "Epoch 32/100\n",
      "1259/1260 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9997\n",
      "Epoch 32: val_accuracy did not improve from 0.97522\n",
      "1260/1260 [==============================] - 15s 12ms/step - loss: 0.0065 - accuracy: 0.9997 - val_loss: 0.1389 - val_accuracy: 0.9596\n",
      "Epoch 33/100\n",
      "1260/1260 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 0.9998\n",
      "Epoch 33: val_accuracy did not improve from 0.97522\n",
      "1260/1260 [==============================] - 15s 12ms/step - loss: 0.0059 - accuracy: 0.9998 - val_loss: 0.1191 - val_accuracy: 0.9656\n",
      "Epoch 34/100\n",
      "1260/1260 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 34: val_accuracy did not improve from 0.97522\n",
      "1260/1260 [==============================] - 15s 12ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0984 - val_accuracy: 0.9723\n",
      "Epoch 35/100\n",
      "1258/1260 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 35: val_accuracy did not improve from 0.97522\n",
      "1260/1260 [==============================] - 16s 12ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1195 - val_accuracy: 0.9667\n",
      "Epoch 36/100\n",
      "1256/1260 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 36: val_accuracy did not improve from 0.97522\n",
      "1260/1260 [==============================] - 15s 12ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0992 - val_accuracy: 0.9710\n",
      "Epoch 37/100\n",
      "1256/1260 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 37: val_accuracy did not improve from 0.97522\n",
      "1260/1260 [==============================] - 16s 12ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1208 - val_accuracy: 0.9652\n",
      "Epoch 38/100\n",
      "1260/1260 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 38: val_accuracy did not improve from 0.97522\n",
      "1260/1260 [==============================] - 15s 12ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1041 - val_accuracy: 0.9712\n",
      "Epoch 39/100\n",
      "1260/1260 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 39: val_accuracy did not improve from 0.97522\n",
      "1260/1260 [==============================] - 15s 12ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1084 - val_accuracy: 0.9710\n",
      "Epoch 40/100\n",
      "1257/1260 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 40: val_accuracy did not improve from 0.97522\n",
      "1260/1260 [==============================] - 15s 12ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1147 - val_accuracy: 0.9679\n",
      "Epoch 41/100\n",
      "1260/1260 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 41: val_accuracy did not improve from 0.97522\n",
      "1260/1260 [==============================] - 15s 12ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1116 - val_accuracy: 0.9692\n",
      "Epoch 42/100\n",
      "1258/1260 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 42: val_accuracy did not improve from 0.97522\n",
      "1260/1260 [==============================] - 15s 12ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1048 - val_accuracy: 0.9712\n",
      "Epoch 43/100\n",
      "1257/1260 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 43: val_accuracy did not improve from 0.97522\n",
      "1260/1260 [==============================] - 15s 12ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1195 - val_accuracy: 0.9674\n",
      "Epoch 44/100\n",
      "1259/1260 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 44: val_accuracy did not improve from 0.97522\n",
      "1260/1260 [==============================] - 15s 12ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1006 - val_accuracy: 0.9714\n",
      "Epoch 45/100\n",
      "1257/1260 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 45: val_accuracy did not improve from 0.97522\n",
      "1260/1260 [==============================] - 15s 12ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1057 - val_accuracy: 0.9708\n",
      "Epoch 46/100\n",
      "1257/1260 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 46: val_accuracy did not improve from 0.97522\n",
      "1260/1260 [==============================] - 15s 12ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1101 - val_accuracy: 0.9708\n",
      "Epoch 47/100\n",
      "1257/1260 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 47: val_accuracy did not improve from 0.97522\n",
      "1260/1260 [==============================] - 15s 12ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1012 - val_accuracy: 0.9717\n",
      "Epoch 48/100\n",
      "1257/1260 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 48: val_accuracy did not improve from 0.97522\n",
      "1260/1260 [==============================] - 15s 12ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1095 - val_accuracy: 0.9708\n",
      "Epoch 49/100\n",
      "1260/1260 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 49: val_accuracy did not improve from 0.97522\n",
      "1260/1260 [==============================] - 15s 12ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1011 - val_accuracy: 0.9721\n",
      "Epoch 49: early stopping\n",
      "350/350 [==============================] - 1s 3ms/step - loss: 0.0922 - accuracy: 0.9713\n",
      "350/350 [==============================] - 1s 4ms/step\n",
      "[0.94299763 0.99218459 0.99965718 0.99817051 0.93443754 0.99309342\n",
      " 0.96818337]\n",
      "[0.92431275 0.98960653 1.         1.         0.93443754 1.\n",
      " 1.        ]\n",
      "CPU times: total: 56min 15s\n",
      "Wall time: 13min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "f1_bp2 = []\n",
    "f1_qp2 = []\n",
    "f1_162 = []\n",
    "f1_642 = []\n",
    "f1_bp4 = []\n",
    "f1_qp4 = []\n",
    "f1_164 = []\n",
    "f1_644 = []\n",
    "\n",
    "ac_bp2 = []\n",
    "ac_qp2 = []\n",
    "ac_162 = []\n",
    "ac_642 = []\n",
    "ac_bp4 = []\n",
    "ac_qp4 = []\n",
    "ac_164 = []\n",
    "ac_644 = []\n",
    "\n",
    "f1_bp = []\n",
    "f1_qp = []\n",
    "f1_16 = []\n",
    "f1_64 = []\n",
    "re_bp = []\n",
    "re_qp = []\n",
    "re_16 = []\n",
    "re_64 = []\n",
    "pr_bp = []\n",
    "pr_qp = []\n",
    "pr_16 = []\n",
    "pr_64 = []\n",
    "ac_bp = []\n",
    "ac_qp = []\n",
    "ac_16 = []\n",
    "ac_64 = []\n",
    "\n",
    "f1mc_bp = []\n",
    "f1mc_qp = []\n",
    "f1mc_16 = []\n",
    "f1mc_64 = []\n",
    "remc_bp = []\n",
    "remc_qp = []\n",
    "remc_16 = []\n",
    "remc_64 = []\n",
    "prmc_bp = []\n",
    "prmc_qp = []\n",
    "prmc_16 = []\n",
    "prmc_64 = []\n",
    "acmc_bp = []\n",
    "acmc_qp = []\n",
    "acmc_16 = []\n",
    "acmc_64 = []\n",
    "\n",
    "accuracy = []\n",
    "f1score = []\n",
    "loss = []\n",
    "precision = []\n",
    "false_pos = []\n",
    "true_pos = []\n",
    "recall = []\n",
    "\n",
    "for LENGTH in symbol_length:\n",
    "    \n",
    "    # Separating X and y\n",
    "    y = df_all['Mod'] # 1D targer vector\n",
    "    X = df_all.drop(columns='Mod')\n",
    "\n",
    "    INPUT_SHAPE = (LENGTH,1)\n",
    "\n",
    "    X.drop(X.iloc[:, LENGTH:2048], inplace = True, axis = 1)\n",
    "\n",
    "    X = np.expand_dims(X, -1)\n",
    "\n",
    "    # Split into training/testing sets with 20% split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=1)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=1) \n",
    "\n",
    "    print(\"..........Training set..........\")\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(\"..........Validation set..........\")\n",
    "    print(X_val.shape)\n",
    "    print(y_val.shape)\n",
    "    print(\"..........Testing set..........\")\n",
    "    print(X_test.shape)\n",
    "    print(y_test.shape)\n",
    "\n",
    "    # Convert class vectors to categorical classes matrices\n",
    "    y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "    y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
    "    y_val = np_utils.to_categorical(y_val, NB_CLASSES)\n",
    "\n",
    "    from keras.constraints import maxnorm\n",
    "\n",
    "    # Function to create model, required for KerasClassifier\n",
    "    def create_model():\n",
    "        # create model\n",
    "        model = Sequential()\n",
    "        filter_num = ['None',32,64,128,256]\n",
    "        kernel_size = ['None',8,8,8,8]\n",
    "        conv_stride_size = ['None',1,1,1,1]\n",
    "        pool_stride_size = ['None',4,4,4,4]\n",
    "        pool_size = ['None',8,8,8,8]\n",
    "        batch_size = 10\n",
    "        dropout_rate =0.0\n",
    "        # Feature extraction\n",
    "        model.add(Conv1D(filters=filter_num[1], kernel_size=kernel_size[1], input_shape=INPUT_SHAPE,\n",
    "                             strides=conv_stride_size[1], padding='same',\n",
    "                             name='convolution1'))\n",
    "        model.add(BatchNormalization(axis=-1))\n",
    "        model.add(ELU(alpha=1.0, name='activation1'))\n",
    "        model.add(MaxPooling1D(pool_size=pool_size[1], strides=pool_stride_size[1],\n",
    "                                   padding='same', name='pool1'))\n",
    "        model.add(Dropout(dropout_rate, name='dropout1'))\n",
    "\n",
    "        # Output layer\n",
    "        model.add(Flatten(name='flatten1'))\n",
    "        model.add(Dense(NB_CLASSES, kernel_initializer=glorot_uniform(seed=0), name='dense1'))\n",
    "        model.add(Activation('softmax', name=\"softmax\"))\n",
    "\n",
    "        # Compile model\n",
    "        model.compile(loss=\"categorical_crossentropy\", optimizer=SGD(lr=0.01, momentum=0.6), metrics=[\"accuracy\"])\n",
    "\n",
    "        return model\n",
    "\n",
    "    model = create_model()\n",
    "    # simple early stopping\n",
    "    es_lr = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
    "    mc_lr = ModelCheckpoint(file_best, monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "    # fit model\n",
    "    model_history = model.fit(X_train, y_train, epochs=NB_EPOCH, verbose=VERBOSE, \n",
    "                                validation_data=(X_val, y_val), callbacks=[es_lr, mc_lr])\n",
    "    \n",
    "    \n",
    "    # Start evaluating model with testing data\n",
    "    score_test = model.evaluate(X_test, y_test, verbose=VERBOSE)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred1=np.argmax(y_pred, axis=1)\n",
    "    y_test1=np.argmax(y_test, axis=1)\n",
    "    cm = confusion_matrix(y_test1, y_pred1)\n",
    "    \n",
    "    acc = score_test[1]\n",
    "    accuracy.append(acc)\n",
    "    \n",
    "    ls = score_test[0]\n",
    "    loss.append(ls)\n",
    "    \n",
    "    f1s = f1_score(y_test1, y_pred1, average=None)\n",
    "    print(f1s)\n",
    "    #f1score.append((f1s[0]+f1s[1])/2)\n",
    "    for index, val in np.ndenumerate(f1s):\n",
    "            if (index[0]==0): \n",
    "                f1b = val\n",
    "            if (index[0]==1): \n",
    "                f1q2 = val\n",
    "            if (index[0]==2):\n",
    "                f1162 = val\n",
    "            if (index[0]==3): \n",
    "                f1642 = val\n",
    "            if (index[0]==4): \n",
    "                f1q4 = val\n",
    "            if (index[0]==5): \n",
    "                f1164 = val\n",
    "            if (index[0]==6): \n",
    "                f1644 = val\n",
    "       \n",
    "\n",
    "    f1_bp.append(f1b)\n",
    "    f1_qp2.append(f1q2)\n",
    "    f1_162.append(f1162)\n",
    "    f1_642.append(f1642)\n",
    "\n",
    "    f1_qp4.append(f1q4)\n",
    "    f1_164.append(f1164)\n",
    "    f1_644.append(f1644)\n",
    "    \n",
    "    \n",
    "    cm = confusion_matrix(y_test1, y_pred1)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    #print('Confusion Matrix when Symbol Length ', LENGTH)\n",
    "    #f = sns.heatmap(cm, cmap='Greens', annot=True, square=True, yticklabels = True)\n",
    "    #cmratio = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    #plt.rcParams[\"figure.figsize\"] = (7.5,7.5)\n",
    "    #plt.rcParams.update({'font.size': 14})\n",
    "    #f = sns.heatmap(cm, cmap='Purples', annot=True, square=True, yticklabels = True)\n",
    "    \n",
    "    accuracys = cm.diagonal()\n",
    "    #acc = accuracy.reshape(-1,1)\n",
    "    print(accuracys)\n",
    "    for index, val in np.ndenumerate(accuracys):\n",
    "            if (index[0]==0): \n",
    "                a1b = val\n",
    "            if (index[0]==1): \n",
    "                a1q2 = val\n",
    "            if (index[0]==2):\n",
    "                a1162 = val\n",
    "            if (index[0]==3): \n",
    "                a1642 = val\n",
    "            if (index[0]==4): \n",
    "                a1q4 = val\n",
    "            if (index[0]==5):\n",
    "                a1164 = val\n",
    "            if (index[0]==6): \n",
    "                a1644 = val\n",
    "    ac_bp.append(a1b)\n",
    "    ac_qp2.append(a1q2)\n",
    "    ac_162.append(a1162)\n",
    "    ac_642.append(a1642)\n",
    "    ac_qp4.append(a1q4)\n",
    "    ac_164.append(a1164)\n",
    "    ac_644.append(a1644)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "oM8aeAQ928gJ",
   "metadata": {
    "id": "oM8aeAQ928gJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbol series length =  500\n",
      "[[2589    7    0    4   94   17   90]\n",
      " [  12 1333    1    0    1    0    0]\n",
      " [   0    0 1458    0    0    0    0]\n",
      " [   0    0    0 1364    0    0    0]\n",
      " [  89    0    0    1 1354    2    3]\n",
      " [   0    0    0    0    0 1366    0]\n",
      " [   0    0    0    0    0    0 1415]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Symbol series length = \", LENGTH)\n",
    "\n",
    "y_pred1=np.argmax(y_pred, axis=1)\n",
    "y_test1=np.argmax(y_test, axis=1)\n",
    "cm = confusion_matrix(y_test1, y_pred1)\n",
    "print(cm)\n",
    "#f = sns.heatmap(cm, cmap='Purples', annot=True, square=True, yticklabels = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "732064f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmratio_short = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "cmratio_short= np.around(cmratio_short.astype('float') / cmratio_short.sum(axis=1)[:, np.newaxis], decimals=1)\n",
    "plt.rcParams[\"figure.figsize\"] = (8,8)\n",
    "plt.rcParams.update({'font.size': 25})\n",
    "f_short = sns.heatmap(cmratio_short, cmap='Purples', annot=True, square=True, yticklabels = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118f35b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "fixedEncrypt-Mixed-2n4state-7class.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
